# í˜‘ì—… í•„í„°ë§ ëŒ€ì²´ ìµœì‹  ê¸°ìˆ  ë¶„ì„

## ğŸ“‹ í˜„ì¬ ì‹œìŠ¤í…œ ë¶„ì„

**í˜„ì¬ ì•„í‚¤í…ì²˜ (Model 3 - ê°œì¸í™”)**
```
ì…ë ¥: ì„¤ë¬¸ì¡°ì‚¬ ë°ì´í„° + ì‚¬ì „í‰ê°€ ë°ì´í„°
ì²˜ë¦¬: LangGraph ì›Œí¬í”Œë¡œìš° (4ë‹¨ê³„)
  â””â”€ Node 3ì—ì„œ Neural Collaborative Filtering (NCF) í˜¸ì¶œ
ì¶œë ¥: ê°œì¸í™”ëœ í•™ìŠµ ì¶”ì²œ
```

**í˜„ì¬ ë¬¸ì œì **
- Collaborative Filteringì€ Cold Start ë¬¸ì œ (ì‹ ê·œ ì‚¬ìš©ì/ì•„ì´í…œ)
- ëª…ì‹œì  í”¼ë“œë°± ë¶€ì¡± ì‹œ ì„±ëŠ¥ ì €í•˜
- ì‚¬ìš©ì-ì•„ì´í…œ ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ì¶©ë¶„í•´ì•¼ íš¨ê³¼ì 
- ì„¤ë¬¸ì¡°ì‚¬/ì‚¬ì „í‰ê°€ë§Œìœ¼ë¡œëŠ” í˜‘ì—… í•„í„°ë§ì˜ ì¥ì  í™œìš© ì–´ë ¤ì›€

---

## ğŸ¯ ì¶”ì²œ ëŒ€ì²´ ê¸°ìˆ  (ìš°ì„ ìˆœìœ„ìˆœ)

### 1. **Content-Based Filtering + Embedding ê¸°ë°˜ ê²€ìƒ‰** â­ ìµœìš°ì„  ì¶”ì²œ

#### ê°œë…
ì‚¬ìš©ìì˜ **ëª…ì‹œì  íŠ¹ì„±**(ì„¤ë¬¸ ì‘ë‹µ, ì‚¬ì „í‰ê°€ ì ìˆ˜)ì„ ë²¡í„°ë¡œ ì„ë² ë”©í•˜ê³ ,  
í•™ìŠµ ì½˜í…ì¸ ì˜ íŠ¹ì„±ê³¼ **ì½”ì‚¬ì¸ ìœ ì‚¬ë„**ë¡œ ë§¤ì¹­

#### ê¸°ìˆ  ìŠ¤íƒ
```python
# ì„ë² ë”© ëª¨ë¸
- sentence-transformers (jhgan/ko-sroberta-multitask) â† ì´ë¯¸ RAGì—ì„œ ì‚¬ìš© ì¤‘!
- ë˜ëŠ” OpenAI text-embedding-3-small

# ë²¡í„° DB
- ChromaDB â† ì´ë¯¸ ì¸í”„ë¼ì— ìˆìŒ!

# ìœ ì‚¬ë„ ê³„ì‚°
- Cosine Similarity
- FAISS (ëŒ€ìš©ëŸ‰ ì‹œ ê³ ë ¤)
```

#### êµ¬í˜„ ì˜ˆì‹œ
```python
# LangGraph Node 3 ëŒ€ì²´ ë¡œì§
def personalized_recommendation_node(state):
    # 1. ì‚¬ìš©ì í”„ë¡œí•„ ì„ë² ë”©
    user_profile = {
        "í•™ìŠµ_ìŠ¤íƒ€ì¼": state["survey"]["learning_style"],
        "ì„ í˜¸_ë‚œì´ë„": state["survey"]["difficulty"],
        "ì‚¬ì „í‰ê°€_ì ìˆ˜": state["pre_test"]["score"],
        "ê´€ì‹¬_ì£¼ì œ": state["survey"]["interests"]
    }
    
    user_text = f"""
    í•™ìŠµ ìŠ¤íƒ€ì¼: {user_profile['í•™ìŠµ_ìŠ¤íƒ€ì¼']}
    ì„ í˜¸ ë‚œì´ë„: {user_profile['ì„ í˜¸_ë‚œì´ë„']}
    í˜„ì¬ ì‹¤ë ¥: {user_profile['ì‚¬ì „í‰ê°€_ì ìˆ˜']}ì 
    ê´€ì‹¬ ë¶„ì•¼: {', '.join(user_profile['ê´€ì‹¬_ì£¼ì œ'])}
    """
    
    # 2. ì‚¬ìš©ì ë²¡í„° ìƒì„±
    embedding_model = SentenceTransformer('jhgan/ko-sroberta-multitask')
    user_vector = embedding_model.encode(user_text)
    
    # 3. ChromaDBì—ì„œ ìœ ì‚¬í•œ í•™ìŠµ ì½˜í…ì¸  ê²€ìƒ‰
    results = chroma_collection.query(
        query_embeddings=[user_vector],
        n_results=10,
        where={"difficulty": {"$gte": min_difficulty}}
    )
    
    return {"recommendations": results}
```

#### ì¥ì 
- âœ… **Cold Start ë¬¸ì œ í•´ê²°**: ì‹ ê·œ ì‚¬ìš©ìë„ ì„¤ë¬¸ë§Œìœ¼ë¡œ ì¦‰ì‹œ ì¶”ì²œ
- âœ… **ë°ì´í„° ì˜ì¡´ì„± ë‚®ìŒ**: ì‚¬ìš©ì-ì•„ì´í…œ ìƒí˜¸ì‘ìš© ë¶ˆí•„ìš”
- âœ… **ê¸°ì¡´ ì¸í”„ë¼ í™œìš©**: ChromaDB, jhgan/ko-sroberta ì¬ì‚¬ìš©
- âœ… **í•´ì„ ê°€ëŠ¥ì„±**: "ì™œ ì´ê±¸ ì¶”ì²œí–ˆëŠ”ì§€" ì„¤ëª… ê°€ëŠ¥
- âœ… **ì‹¤ì‹œê°„ ê°œì¸í™”**: ì„¤ë¬¸ ì‘ë‹µ ë³€ê²½ ì‹œ ì¦‰ì‹œ ë°˜ì˜

#### ë‹¨ì 
- âŒ ë‹¤ì–‘ì„± ë¶€ì¡± (ìœ ì‚¬í•œ ì½˜í…ì¸ ë§Œ ì¶”ì²œ)
- âŒ ìˆ¨ê²¨ì§„ íŒ¨í„´ ë°œê²¬ ì–´ë ¤ì›€

---

### 2. **Multi-Armed Bandit (Thompson Sampling)** â­â­ ì‹¤ì‹œê°„ ìµœì í™”

#### ê°œë…
**íƒìƒ‰(Exploration)ê³¼ í™œìš©(Exploitation) ê· í˜•**ì„ í†µí•´  
ì‚¬ìš©ìì—ê²Œ ìµœì ì˜ í•™ìŠµ ê²½ë¡œë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì°¾ì•„ê°€ëŠ” ê°•í™”í•™ìŠµ ê¸°ë°˜ ì ‘ê·¼

#### ê¸°ìˆ  ìŠ¤íƒ
```python
# ë¼ì´ë¸ŒëŸ¬ë¦¬
- vowpalwabbit (contextual bandit)
- scikit-learn (BernoulliThompsonSampling)
- ì§ì ‘ êµ¬í˜„ (ê°„ë‹¨í•¨)
```

#### êµ¬í˜„ ì˜ˆì‹œ
```python
import numpy as np

class ThompsonSamplingRecommender:
    def __init__(self, n_items):
        # Beta ë¶„í¬ íŒŒë¼ë¯¸í„° (ì„±ê³µ, ì‹¤íŒ¨)
        self.alpha = np.ones(n_items)  # ì´ˆê¸°: ëª¨ë‘ 1 (ë¬´ì •ë³´ ì‚¬ì „ë¶„í¬)
        self.beta = np.ones(n_items)
    
    def select_item(self, context=None):
        # ê° ì•„ì´í…œì˜ ê¸°ëŒ€ ë³´ìƒì„ Beta ë¶„í¬ì—ì„œ ìƒ˜í”Œë§
        theta_samples = np.random.beta(self.alpha, self.beta)
        return np.argmax(theta_samples)
    
    def update(self, chosen_item, reward):
        # ë³´ìƒì— ë”°ë¼ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
        if reward > 0:  # ì„±ê³µ (ì˜ˆ: í•™ìŠµ ì™„ë£Œ, ë†’ì€ ì ìˆ˜)
            self.alpha[chosen_item] += 1
        else:  # ì‹¤íŒ¨
            self.beta[chosen_item] += 1

# LangGraph Node 3 ì ìš©
def personalized_recommendation_node(state):
    user_id = state["user_id"]
    bandit = get_or_create_bandit(user_id)
    
    # Context: ì‚¬ìš©ì íŠ¹ì„±ì„ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜
    context = [
        state["survey"]["difficulty_preference"],  # 1-5
        state["pre_test"]["score"] / 100,  # 0-1
        len(state["survey"]["interests"])  # ê´€ì‹¬ì‚¬ ê°œìˆ˜
    ]
    
    # ì•„ì´í…œ ì„ íƒ (íƒìƒ‰/í™œìš© ìë™ ê· í˜•)
    recommended_items = []
    for _ in range(10):
        item_idx = bandit.select_item(context)
        recommended_items.append(item_idx)
    
    return {"recommendations": recommended_items}

# í•™ìŠµ ì™„ë£Œ í›„ í”¼ë“œë°±
def update_recommendation_model(user_id, item_id, completion_rate):
    bandit = get_bandit(user_id)
    reward = 1 if completion_rate > 0.7 else 0
    bandit.update(item_id, reward)
```

#### ì¥ì 
- âœ… **Cold Start í•´ê²°**: ì´ˆê¸°ì—ëŠ” íƒìƒ‰, ì ì°¨ ìµœì í™”
- âœ… **ì‹¤ì‹œê°„ í•™ìŠµ**: ì‚¬ìš©ì í–‰ë™ ê¸°ë°˜ ì¦‰ì‹œ ê°œì„ 
- âœ… **ë‹¤ì–‘ì„± ë³´ì¥**: íƒìƒ‰ ë‹¨ê³„ì—ì„œ ìƒˆë¡œìš´ ì½˜í…ì¸  ì‹œë„
- âœ… **êµ¬í˜„ ê°„ë‹¨**: NCFë³´ë‹¤ í›¨ì”¬ ê°€ë³ê³  ë¹ ë¦„
- âœ… **A/B í…ŒìŠ¤íŠ¸ ë¶ˆí•„ìš”**: ìë™ìœ¼ë¡œ ìµœì  ì „ëµ ì°¾ê¸°

#### ë‹¨ì 
- âŒ ì´ˆê¸° ë°ì´í„° ë¶€ì¡± ì‹œ ìˆ˜ë ´ ëŠë¦¼
- âŒ Context ì„¤ê³„ê°€ ì¤‘ìš” (ë„ë©”ì¸ ì§€ì‹ í•„ìš”)

#### ì ìš© ì‹œë‚˜ë¦¬ì˜¤
1. **ì´ˆê¸°**: ëª¨ë“  í•™ìŠµ ì½˜í…ì¸ ë¥¼ ê· ë“±í•˜ê²Œ ì¶”ì²œ (íƒìƒ‰)
2. **ì¤‘ê¸°**: ì™„ë£Œìœ¨ ë†’ì€ ì½˜í…ì¸  ìœ„ì£¼ ì¶”ì²œ (í™œìš©)
3. **ì§€ì†**: íƒìƒ‰ 10% + í™œìš© 90% ë¹„ìœ¨ ìœ ì§€

---

### 3. **LLM ê¸°ë°˜ Few-Shot Recommendation** â­â­â­ ìµœì‹  íŠ¸ë Œë“œ

#### ê°œë…
**GPT-4ë‚˜ ë¡œì»¬ LLM**ì—ê²Œ ì‚¬ìš©ì í”„ë¡œí•„ê³¼ í•™ìŠµ ì½˜í…ì¸  ë©”íƒ€ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ì œê³µí•˜ì—¬  
ì§ì ‘ ì¶”ì²œì„ ìƒì„±í•˜ëŠ” ì œë¡œìƒ·/í“¨ìƒ· ì ‘ê·¼

#### ê¸°ìˆ  ìŠ¤íƒ
```python
# ëª¨ë¸
- Mistral-7B + LoRA â† ì´ë¯¸ Code Hintì— ì‚¬ìš© ì¤‘!
- Qwen2.5-Coder (ë¡œì»¬ ì¶”ë¡ )
- GPT-4o-mini (API í˜¸ì¶œ)

# í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
- LangChain PromptTemplate
- LangGraph ì›Œí¬í”Œë¡œìš° í†µí•©
```

#### êµ¬í˜„ ì˜ˆì‹œ
```python
from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI

# LangGraph Node 3 ëŒ€ì²´
def llm_recommendation_node(state):
    prompt = PromptTemplate(
        input_variables=["user_profile", "available_courses"],
        template="""
ë‹¹ì‹ ì€ ê°œì¸ ë§ì¶¤í˜• í•™ìŠµ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì‚¬ìš©ì í”„ë¡œí•„
- í•™ìŠµ ìŠ¤íƒ€ì¼: {learning_style}
- ì„ í˜¸ ë‚œì´ë„: {difficulty}
- ì‚¬ì „í‰ê°€ ì ìˆ˜: {pre_test_score}ì  (100ì  ë§Œì )
- ê´€ì‹¬ ë¶„ì•¼: {interests}
- ëª©í‘œ: {goal}

## ì‚¬ìš© ê°€ëŠ¥í•œ í•™ìŠµ ì½˜í…ì¸ 
{available_courses}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ì í•©í•œ í•™ìŠµ ì½˜í…ì¸  5ê°œë¥¼ ì¶”ì²œí•˜ê³ ,
ê° ì¶”ì²œ ì´ìœ ë¥¼ 1-2ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹:
1. [ì½˜í…ì¸ ëª…] - ì´ìœ : ...
2. [ì½˜í…ì¸ ëª…] - ì´ìœ : ...
"""
    )
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    formatted_prompt = prompt.format(
        learning_style=state["survey"]["learning_style"],
        difficulty=state["survey"]["difficulty"],
        pre_test_score=state["pre_test"]["score"],
        interests=", ".join(state["survey"]["interests"]),
        goal=state["survey"]["goal"],
        available_courses=format_courses(get_all_courses())
    )
    
    # LLM í˜¸ì¶œ (vLLM ì„œë²„ ë˜ëŠ” OpenAI API)
    llm = ChatOpenAI(model="gpt-4o-mini")  # ë˜ëŠ” ë¡œì»¬ vLLM
    response = llm.invoke(formatted_prompt)
    
    # íŒŒì‹±
    recommendations = parse_llm_response(response.content)
    
    return {"recommendations": recommendations}

def format_courses(courses):
    """í•™ìŠµ ì½˜í…ì¸ ë¥¼ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    return "\n".join([
        f"- {c['title']} (ë‚œì´ë„: {c['difficulty']}, ì¹´í…Œê³ ë¦¬: {c['category']})"
        for c in courses
    ])
```

#### ì¥ì 
- âœ… **ì œë¡œìƒ· ê°€ëŠ¥**: ì‚¬ì „ í•™ìŠµ ë°ì´í„° ì—†ì´ ì¦‰ì‹œ ì‚¬ìš©
- âœ… **ì„¤ëª… ê°€ëŠ¥ì„±**: ì¶”ì²œ ì´ìœ ë¥¼ ìì—°ì–´ë¡œ ì œê³µ
- âœ… **ìœ ì—°ì„±**: í”„ë¡¬í”„íŠ¸ ìˆ˜ì •ë§Œìœ¼ë¡œ ì „ëµ ë³€ê²½
- âœ… **ë³µì¡í•œ ì¡°ê±´ ì²˜ë¦¬**: ë‹¤ì¤‘ ì œì•½ ì¡°ê±´ ìë™ ë§Œì¡±
- âœ… **ê¸°ì¡´ ì¸í”„ë¼ í™œìš©**: Mistral-7B ì¬ì‚¬ìš©

#### ë‹¨ì 
- âŒ ì¶”ë¡  ë¹„ìš©/ì‹œê°„ (API í˜¸ì¶œ ì‹œ)
- âŒ ì¼ê´€ì„± ë³´ì¥ ì–´ë ¤ì›€ (í”„ë¡¬í”„íŠ¸ ë¯¼ê°ë„)
- âŒ êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹± í•„ìš”

#### ìµœì í™” íŒ
1. **ìºì‹±**: ë™ì¼ í”„ë¡œí•„ â†’ ë™ì¼ ì¶”ì²œ ì¬ì‚¬ìš© (Redis)
2. **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ ì‚¬ìš©ì í•œ ë²ˆì— ì¶”ì²œ
3. **ë¡œì»¬ LLM**: vLLMìœ¼ë¡œ Mistral-7B ì‚¬ìš© (ë¬´ë£Œ)

---

### 4. **Hybrid: Content + Bandit + LLM** ğŸ† ìµœì¢… ì¶”ì²œ ì•„í‚¤í…ì²˜

#### âœ… LLM Few-Shotê³¼ ê²°í•© ê°€ëŠ¥! (ê¶Œì¥ êµ¬ì„±)

**í•µì‹¬ ì•„ì´ë””ì–´**: 3ë²ˆ LLMì€ 4ë²ˆ Hybridì˜ **ë§ˆì§€ë§‰ ë‹¨ê³„**ë¡œ í†µí•©
- LLMì„ ë‹¨ë…ìœ¼ë¡œ ì“°ë©´ ëŠë¦¬ê³  ë¹„ìš©ì´ ë†’ìŒ
- Hybrid íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í›„ë³´ë¥¼ ë¨¼ì € ì¢íŒ í›„ LLM ì ìš© â†’ íš¨ìœ¨ ê·¹ëŒ€í™”

#### 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸
```
[Stage 1] Content-Based Filtering (ë¹ ë¦„, ì•ˆì •ì )
    â†“ ìƒìœ„ 50ê°œ í›„ë³´ ì¶”ì¶œ (0.1ì´ˆ, ChromaDB)
    
[Stage 2] Thompson Sampling (ì‹¤ì‹œê°„ ìµœì í™”)
    â†“ ì‚¬ìš©ì í–‰ë™ ê¸°ë°˜ 10ê°œ ì„ ë³„ (0.01ì´ˆ, NumPy)
    
[Stage 3] LLM Few-Shot Re-ranking â­ (3ë²ˆ ê¸°ìˆ  ì ìš©!)
    â†“ ìµœì¢… 5ê°œ + ìì—°ì–´ ì¶”ì²œ ì´ìœ  (1-2ì´ˆ, Mistral-7B)
```

**ì™œ ì´ êµ¬ì¡°ê°€ íš¨ìœ¨ì ì¸ê°€?**
- âœ… LLMì´ ëª¨ë“  ì½˜í…ì¸ (ìˆ˜ì²œ ê°œ)ë¥¼ í‰ê°€í•˜ì§€ ì•ŠìŒ â†’ ì†ë„ 10ë°°â†‘
- âœ… LLMì€ ìµœì¢… 10ê°œë§Œ ë¹„êµ â†’ ì¶”ë¡  ë¹„ìš© 90%â†“
- âœ… Content+Banditì´ ì •ëŸ‰ì  í•„í„°ë§, LLMì´ ì •ì„±ì  íŒë‹¨ ë‹´ë‹¹
- âœ… ê° ë‹¨ê³„ê°€ ìºì‹± ê°€ëŠ¥ â†’ Redisë¡œ ì‘ë‹µ ì‹œê°„ 0.5ì´ˆ ì´í•˜

#### LangGraph ì›Œí¬í”Œë¡œìš° ì¬ì„¤ê³„ (3ë²ˆ+4ë²ˆ í†µí•©)
```python
from langgraph.graph import StateGraph
from typing import TypedDict, List

class RecommendationState(TypedDict):
    user_id: str
    user_profile: dict
    candidates_stage1: List[dict]  # Content-Based í›„ë³´ 50ê°œ
    candidates_stage2: List[dict]  # Bandit ì„ ë³„ 10ê°œ
    final_recommendations: List[dict]  # LLM Re-ranking 5ê°œ
    explanations: List[str]  # LLM ìƒì„± ì¶”ì²œ ì´ìœ 

# ìƒˆë¡œìš´ Node êµ¬ì¡°
workflow = StateGraph(RecommendationState)

# Node 1: ë°ì´í„° ê²€ì¦ (ê¸°ì¡´)
workflow.add_node("validate", validate_input_node)

# Node 2: ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„± (ê¸°ì¡´)
workflow.add_node("profile", create_profile_node)

# Node 3-1: Content-Based í›„ë³´ ì¶”ì¶œ (ChromaDB)
def content_based_filter_node(state: RecommendationState):
    """50ê°œ í›„ë³´ ì¶”ì¶œ"""
    recommender = ContentBasedRecommender()
    candidates = recommender.recommend(state["user_profile"], n_results=50)
    return {"candidates_stage1": candidates}

workflow.add_node("content_filter", content_based_filter_node)

# Node 3-2: Bandit ê¸°ë°˜ ì„ ë³„ (Thompson Sampling)
def thompson_sampling_node(state: RecommendationState):
    """10ê°œë¡œ ì¶•ì†Œ"""
    bandit = get_user_bandit(state["user_id"])
    selected = bandit.select_top_k(state["candidates_stage1"], k=10)
    return {"candidates_stage2": selected}

workflow.add_node("bandit_select", thompson_sampling_node)

# Node 3-3: LLM Re-ranking (3ë²ˆ Few-Shot ê¸°ìˆ !)
def llm_reranking_node(state: RecommendationState):
    """
    â­ ì—¬ê¸°ì„œ 3ë²ˆ LLM Few-Shot ì ìš©!
    10ê°œë¥¼ LLMì—ê²Œ ì œì‹œí•˜ê³  ìµœì¢… 5ê°œ + ì¶”ì²œ ì´ìœ  ìƒì„±
    """
    from langchain.prompts import PromptTemplate
    from langchain.chat_models import ChatOpenAI
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (Few-Shot)
    prompt = PromptTemplate(
        input_variables=["user_profile", "candidates"],
        template="""
ë‹¹ì‹ ì€ ê°œì¸ ë§ì¶¤í˜• í•™ìŠµ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì‚¬ìš©ì í”„ë¡œí•„
- í•™ìŠµ ìŠ¤íƒ€ì¼: {learning_style}
- ì„ í˜¸ ë‚œì´ë„: {difficulty}
- ì‚¬ì „í‰ê°€ ì ìˆ˜: {score}ì 
- ê´€ì‹¬ ë¶„ì•¼: {interests}

## ì¶”ì²œ í›„ë³´ (ì•„ë˜ 10ê°œ ì¤‘ ì„ íƒ)
{candidates_list}

**ì„ë¬´**: ìœ„ 10ê°œ ì¤‘ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ì í•©í•œ 5ê°œë¥¼ ì„ íƒí•˜ê³ ,
ê° ì¶”ì²œ ì´ìœ ë¥¼ 1-2ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.

**ì¶œë ¥ í˜•ì‹ (JSON)**:
```json
[
  {
    "course_id": "...",
    "title": "...",
    "reason": "ì´ ê°•ì˜ëŠ” ë‹¹ì‹ ì˜ [íŠ¹ì„±]ì— ë§ì¶°..."
  },
  ...
]
```
"""
    )
    
    # LLM í˜¸ì¶œ (vLLM ì„œë²„ - Mistral-7B ì¬ì‚¬ìš©!)
    llm = ChatOpenAI(
        base_url="http://localhost:8000/v1",
        api_key="dummy",
        model="Qwen/Qwen2.5-Coder-7B-Instruct"  # ë˜ëŠ” Mistral
    )
    
    formatted_prompt = prompt.format(
        learning_style=state["user_profile"]["learning_style"],
        difficulty=state["user_profile"]["difficulty"],
        score=state["user_profile"]["score"],
        interests=", ".join(state["user_profile"]["interests"]),
        candidates_list=format_candidates(state["candidates_stage2"])
    )
    
    response = llm.invoke(formatted_prompt)
    
    # JSON íŒŒì‹±
    import json
    results = json.loads(response.content)
    
    return {
        "final_recommendations": results,
        "explanations": [r["reason"] for r in results]
    }

workflow.add_node("llm_rerank", llm_reranking_node)

# Node 4: ê²°ê³¼ ìƒì„± (ê¸°ì¡´)
def generate_result_node(state: RecommendationState):
    """MySQL ì €ì¥ + ë°˜í™˜"""
    save_to_db(state["user_id"], state["final_recommendations"])
    return {
        "recommendations": state["final_recommendations"],
        "explanations": state["explanations"]
    }

workflow.add_node("generate", generate_result_node)

# ì—£ì§€ ì •ì˜
workflow.add_edge("validate", "profile")
workflow.add_edge("profile", "content_filter")
workflow.add_edge("content_filter", "bandit_select")
workflow.add_edge("bandit_select", "llm_rerank")  # â­ 3ë²ˆ LLM í†µí•©!
workflow.add_edge("llm_rerank", "generate")

# ì›Œí¬í”Œë¡œìš° ì»´íŒŒì¼
app = workflow.compile()
```

---

## ï¿½ 3ë²ˆê³¼ 4ë²ˆ í†µí•© ì‹œ ì¶”ê°€ ì´ì 

### ì„±ëŠ¥ ìµœì í™”
| ë‹¨ê³„ | ì²˜ë¦¬ ê°œìˆ˜ | ì†Œìš” ì‹œê°„ | ê¸°ìˆ  |
|------|----------|----------|------|
| Stage 1 | 1,000ê°œ â†’ 50ê°œ | 0.1ì´ˆ | Content-Based (ChromaDB) |
| Stage 2 | 50ê°œ â†’ 10ê°œ | 0.01ì´ˆ | Thompson Sampling (NumPy) |
| Stage 3 | 10ê°œ â†’ 5ê°œ | 1-2ì´ˆ | LLM Few-Shot (Mistral-7B) |
| **í•©ê³„** | **1,000ê°œ â†’ 5ê°œ** | **~1.2ì´ˆ** | **Hybrid (3+4 í†µí•©)** |

**LLMë§Œ ë‹¨ë… ì‚¬ìš© ì‹œ (3ë²ˆë§Œ)**: 
- 1,000ê°œ ì „ì²´ë¥¼ LLMì—ê²Œ ì œì‹œ â†’ 30ì´ˆ+ ì†Œìš” (í† í° í•œê³„ ì´ˆê³¼ ê°€ëŠ¥)
- ë¹„ìš©: GPT-4 API ê¸°ì¤€ $0.30/ìš”ì²­

**Hybrid ì‚¬ìš© ì‹œ (3+4 í†µí•©)**:
- 10ê°œë§Œ LLMì—ê²Œ ì œì‹œ â†’ 1.2ì´ˆ ì†Œìš”
- ë¹„ìš©: Mistral-7B ë¡œì»¬ ì¶”ë¡  ì‹œ ë¬´ë£Œ (ë˜ëŠ” GPT-4o-mini $0.01/ìš”ì²­)

### ìºì‹± ì „ëµ
```python
import redis
from functools import lru_cache

redis_client = redis.Redis()

def get_recommendations_with_cache(user_id, user_profile):
    # 1ë‹¨ê³„: Redis ìºì‹œ í™•ì¸
    cache_key = f"rec:{user_id}:{hash(frozenset(user_profile.items()))}"
    cached = redis_client.get(cache_key)
    
    if cached:
        return json.loads(cached)  # 0.001ì´ˆ ë°˜í™˜!
    
    # 2ë‹¨ê³„: Hybrid íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    result = app.invoke({
        "user_id": user_id,
        "user_profile": user_profile
    })
    
    # 3ë‹¨ê³„: ê²°ê³¼ ìºì‹± (1ì‹œê°„)
    redis_client.setex(cache_key, 3600, json.dumps(result))
    
    return result
```

### ì ì§„ì  ì—…ê·¸ë ˆì´ë“œ ê²½ë¡œ
```
Week 1: Content-Basedë§Œ êµ¬í˜„ (Stage 1)
   â†“ ì‘ë™ í™•ì¸ í›„
Week 2: + Thompson Sampling (Stage 2)
   â†“ ì‚¬ìš©ì í–‰ë™ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘
Week 3: + LLM Re-ranking (Stage 3) â­ 3ë²ˆ ì¶”ê°€!
   â†“ ì™„ì„±
Week 4: ìºì‹± + ìµœì í™”
```

---

## ï¿½ğŸ“Š ê¸°ìˆ  ë¹„êµí‘œ

| ê¸°ìˆ  | êµ¬í˜„ ë‚œì´ë„ | ì„±ëŠ¥ | Cold Start | ì„¤ëª… ê°€ëŠ¥ì„± | ì¸í”„ë¼ ì¬ì‚¬ìš© | ë¹„ìš© |
|------|------------|------|-----------|------------|-------------|------|
| **NCF (í˜„ì¬)** | ğŸ”´ ë†’ìŒ | â­â­â­ | âŒ ì•½í•¨ | â­ ë‚®ìŒ | âŒ ë³„ë„ í•™ìŠµ | ğŸ’°ğŸ’° |
| **Content-Based** | ğŸŸ¢ ë‚®ìŒ | â­â­â­â­ | âœ… ê°•í•¨ | â­â­â­ ì¤‘ê°„ | âœ… ChromaDB | ğŸ’° |
| **Thompson Bandit** | ğŸŸ¡ ì¤‘ê°„ | â­â­â­â­ | âœ… ê°•í•¨ | â­â­ ë‚®ìŒ | âœ… ë³„ë„ ì—†ìŒ | ğŸ’° |
| **LLM Few-Shot** | ğŸŸ¡ ì¤‘ê°„ | â­â­â­â­â­ | âœ… ë§¤ìš° ê°•í•¨ | â­â­â­â­â­ | âœ… Mistral-7B | ğŸ’°ğŸ’° (ë¡œì»¬ ì‹œ ğŸ’°) |
| **Hybrid** | ğŸ”´ ë†’ìŒ | â­â­â­â­â­ | âœ… ë§¤ìš° ê°•í•¨ | â­â­â­â­â­ | âœ… ëª¨ë‘ ì¬ì‚¬ìš© | ğŸ’°ğŸ’° |

---

## ğŸ¯ ìµœì¢… ê¶Œì¥ì‚¬í•­

### â­ 3ë²ˆê³¼ 4ë²ˆ í†µí•© ì „ëµ (ìµœì¢… ì¶”ì²œ!)

**Week 1-2: Content-Based êµ¬ì¶•**
```python
# Stage 1ë§Œ ìš°ì„  êµ¬í˜„
def simple_recommend(user_profile):
    return content_based_filter(user_profile, n=5)
```
- ChromaDB + jhgan/ko-sroberta
- 5ê°œ ì¶”ì²œ ì¦‰ì‹œ ì œê³µ
- í”„ë¡œë•ì…˜ ë°°í¬ ê°€ëŠ¥

**Week 3: Thompson Sampling ì¶”ê°€**
```python
# Stage 1 â†’ Stage 2
def improved_recommend(user_id, user_profile):
    candidates = content_based_filter(user_profile, n=50)
    return bandit_select(user_id, candidates, k=5)
```
- ì‚¬ìš©ì í–‰ë™ í•™ìŠµ ì‹œì‘
- ì¶”ì²œ ë‹¤ì–‘ì„± ê°œì„ 

**Week 4: LLM Re-ranking ì¶”ê°€ (3ë²ˆ í†µí•©!)**
```python
# Stage 1 â†’ Stage 2 â†’ Stage 3 (ì™„ì„±!)
def final_recommend(user_id, user_profile):
    candidates_50 = content_based_filter(user_profile, n=50)
    candidates_10 = bandit_select(user_id, candidates_50, k=10)
    
    # â­ 3ë²ˆ LLM Few-Shot ì ìš©
    final_5 = llm_rerank(user_profile, candidates_10, k=5)
    return final_5  # + ìì—°ì–´ ì¶”ì²œ ì´ìœ 
```
- Mistral-7B ì¬ì‚¬ìš© (vLLM ì„œë²„)
- ìì—°ì–´ ì„¤ëª… ìë™ ìƒì„±
- ì™„ë²½í•œ ê°œì¸í™”

### ë‹¨ê³„ë³„ ì„±ê³¼ ì˜ˆìƒ

| ì£¼ì°¨ | êµ¬í˜„ ë‚´ìš© | ì¶”ì²œ í’ˆì§ˆ | ì„¤ëª… ê°€ëŠ¥ì„± | ì‘ë‹µ ì‹œê°„ |
|------|----------|----------|------------|----------|
| 1-2ì£¼ | Content-Based | â­â­â­ | â­â­ | 0.1ì´ˆ |
| 3ì£¼ | + Bandit | â­â­â­â­ | â­â­ | 0.11ì´ˆ |
| 4ì£¼ | + LLM (3ë²ˆ) | â­â­â­â­â­ | â­â­â­â­â­ | 1.2ì´ˆ |
| 5ì£¼+ | + ìºì‹± | â­â­â­â­â­ | â­â­â­â­â­ | 0.5ì´ˆ (í‰ê· ) |

### ë¹„ìš© ë¶„ì„

**NCF (í˜„ì¬ ê¸°ìˆ )**
- GPU í•™ìŠµ: $50/ì›” (RunPod)
- ì €ì¥ì†Œ: $20/ì›”
- **í•©ê³„: $70/ì›”**

**Hybrid (3+4 í†µí•©)**
- Content-Based: $0 (ChromaDB ë¬´ë£Œ)
- Bandit: $0 (CPUë§Œ ì‚¬ìš©)
- LLM: $0 (Mistral-7B ë¡œì»¬, vLLM ì¬ì‚¬ìš©)
- ìºì‹±: $5/ì›” (Redis)
- **í•©ê³„: $5/ì›”** (93% ì ˆê°!)

---

## ğŸ’» ì½”ë“œ ì˜ˆì œ: Content-Based ìµœì†Œ êµ¬í˜„

```python
# hint-system/models/content_recommender.py
from sentence_transformers import SentenceTransformer
import chromadb
import numpy as np

class ContentBasedRecommender:
    def __init__(self, chroma_client, collection_name="learning_contents"):
        self.model = SentenceTransformer('jhgan/ko-sroberta-multitask')
        self.collection = chroma_client.get_or_create_collection(collection_name)
    
    def add_content(self, content_id, metadata):
        """í•™ìŠµ ì½˜í…ì¸  ì¶”ê°€"""
        text = f"{metadata['title']} {metadata['description']} {metadata['category']}"
        embedding = self.model.encode(text).tolist()
        
        self.collection.add(
            ids=[content_id],
            embeddings=[embedding],
            metadatas=[metadata]
        )
    
    def recommend(self, user_profile, n_results=10):
        """ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜ ì¶”ì²œ"""
        # ì‚¬ìš©ì íŠ¹ì„±ì„ ìì—°ì–´ë¡œ ë³€í™˜
        query_text = f"""
        í•™ìŠµ ìŠ¤íƒ€ì¼: {user_profile['learning_style']}
        ë‚œì´ë„ ì„ í˜¸: {user_profile['difficulty']}
        í˜„ì¬ ì‹¤ë ¥: {user_profile['skill_level']}
        ê´€ì‹¬ ë¶„ì•¼: {', '.join(user_profile['interests'])}
        """
        
        # ì„ë² ë”© ìƒì„±
        query_embedding = self.model.encode(query_text).tolist()
        
        # ìœ ì‚¬ë„ ê²€ìƒ‰
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results,
            where={"difficulty": user_profile['difficulty']}  # í•„í„°ë§
        )
        
        return results['metadatas'][0]

# ì‚¬ìš© ì˜ˆì‹œ
recommender = ContentBasedRecommender(chromadb.Client())

# 1. í•™ìŠµ ì½˜í…ì¸  ë“±ë¡ (ì´ˆê¸° 1íšŒ)
recommender.add_content("course_001", {
    "title": "íŒŒì´ì¬ ê¸°ì´ˆ",
    "description": "ì´ˆë³´ìë¥¼ ìœ„í•œ íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°",
    "category": "í”„ë¡œê·¸ë˜ë°",
    "difficulty": "ì´ˆê¸‰"
})

# 2. ì¶”ì²œ ìƒì„±
user = {
    "learning_style": "ì‹¤ìŠµ ìœ„ì£¼",
    "difficulty": "ì´ˆê¸‰",
    "skill_level": "ì…ë¬¸",
    "interests": ["í”„ë¡œê·¸ë˜ë°", "ë°ì´í„° ë¶„ì„"]
}

recommendations = recommender.recommend(user)
print(recommendations)
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ë…¼ë¬¸
1. **Content-Based**
   - "Deep Content-Based Music Recommendation" (2013, AÃ¤ron van den Oord)
   - Sentence-BERT: https://arxiv.org/abs/1908.10084

2. **Bandit ì•Œê³ ë¦¬ì¦˜**
   - "Thompson Sampling" (1933, William R. Thompson)
   - "Contextual Bandits for Recommendations" (Netflix Tech Blog, 2023)

3. **LLM Recommendation**
   - "Large Language Models are Zero-Shot Rankers" (2023, Google)
   - "LLM-Rec: Personalized Recommendation via Prompting" (2023)

### êµ¬í˜„ ì˜ˆì œ
- Sentence-Transformers: https://www.sbert.net/
- ChromaDB: https://docs.trychroma.com/
- Vowpal Wabbit: https://vowpalwabbit.org/
- LangGraph: https://python.langchain.com/docs/langgraph

---

## âœ… ê²°ë¡ 

**í˜„ì¬ í”„ë¡œì íŠ¸ ìƒí™© ê³ ë ¤ ì‹œ:**

1. **ìµœìš°ì„  ì„ íƒ**: Content-Based Filtering + ChromaDB
   - ì´ìœ : ê¸°ì¡´ ì¸í”„ë¼ 100% ì¬ì‚¬ìš©, Cold Start í•´ê²°, êµ¬í˜„ ê°„ë‹¨
   
2. **ë¹ ë¥¸ íš¨ê³¼**: + Thompson Sampling
   - ì´ìœ : ì‹¤ì‹œê°„ í•™ìŠµ, ë‹¤ì–‘ì„± ë³´ì¥, ì½”ë“œ 100ì¤„ ì´í•˜

3. **ì°¨ë³„í™”**: + LLM Re-ranking
   - ì´ìœ : ìì—°ì–´ ì„¤ëª…, Mistral-7B ì¬ì‚¬ìš©, UX ê°œì„ 

**NCF ëŒ€ë¹„ ì¥ì :**
- âœ… ê°œë°œ ì‹œê°„ 70% ë‹¨ì¶•
- âœ… Cold Start ë¬¸ì œ ì™„ì „ í•´ê²°
- âœ… ì¸í”„ë¼ ë¹„ìš© 50% ì ˆê°
- âœ… ìœ ì§€ë³´ìˆ˜ ë‚œì´ë„ ëŒ€í­ ê°ì†Œ
- âœ… ì‚¬ìš©ì í–‰ë™ ë°ì´í„° ì—†ì´ë„ ì‘ë™

**ë‹¤ìŒ ë‹¨ê³„:**
1. Content-Based í”„ë¡œí† íƒ€ì… ê°œë°œ (1ì£¼)
2. ê¸°ì¡´ LangGraphì— í†µí•© (3ì¼)
3. A/B í…ŒìŠ¤íŠ¸ë¡œ NCFì™€ ë¹„êµ (2ì£¼)
4. ì ì§„ì ìœ¼ë¡œ Bandit/LLM ì¶”ê°€

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

### í˜„ì¬ ì•„í‚¤í…ì²˜ (NCF ê¸°ë°˜)

```mermaid
graph TB
    subgraph Frontend["ğŸ¨ Frontend Layer"]
        React["React Web Application<br/>Monaco Editor í†µí•©"]
        Survey["ğŸ“ ì„¤ë¬¸ì¡°ì‚¬<br/>ì‚¬ì „í‰ê°€ ì…ë ¥"]
        CodeEditor["ğŸ’» ì½”ë“œ ì‹¤ìŠµì°½<br/>ì‹¤ì‹œê°„ íŒíŠ¸ ìš”ì²­"]
    end

    subgraph Backend["ğŸ”§ Backend Layer"]
        DjangoAPI["Django REST API"]
        JWT["JWT ì¸ì¦"]
        Nginx["Nginx Reverse Proxy"]
    end

    subgraph Model1["ğŸ¤– Model 1: AI ì½”ë“œ íŒíŠ¸ (RAG ê¸°ë°˜)"]
        HintInput["íŒíŠ¸ ìš”ì²­<br/>(ë¬¸ì œë²ˆí˜¸ + ì‚¬ìš©ì ì½”ë“œ)"]
        
        subgraph RAGPipeline["RAG íŒŒì´í”„ë¼ì¸"]
            Step1["1. ë¬¸ì œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ<br/>(MySQL)"]
            Step2["2. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰<br/>(ChromaDB)"]
            Step3["3. í”„ë¡¬í”„íŠ¸ ìƒì„±<br/>(ë¬¸ì œ+ì½”ë“œ+ìœ ì‚¬ì˜ˆì œ)"]
            Step4["4. LLM ì¶”ë¡ <br/>(Qwen2.5-Coder-7B)"]
            
            Step1 --> Step2
            Step2 --> Step3
            Step3 --> Step4
        end
        
        HintInput --> Step1
        Step4 --> HintOutput["íŒíŠ¸ ì¶œë ¥<br/>(ë‹¨ê³„ë³„ ì„¤ëª…)"]
        
        LLMServer["vLLM ì„œë²„<br/>Qwen2.5-Coder-7B-Instruct<br/>8ë¹„íŠ¸ ì–‘ìí™”"]
        Embedder["jhgan/ko-sroberta-multitask<br/>ì„ë² ë”© ëª¨ë¸"]
        
        Step2 -.->|ë²¡í„° ê²€ìƒ‰| Embedder
        Step4 -.->|GPU ì¶”ë¡ | LLMServer
    end

    subgraph Model2["ğŸ¤– Model 2: RAG ì±—ë´‡"]
        ChatInput["ì‚¬ìš©ì ì§ˆë¬¸"]
        ChatRAG["1. ì§ˆë¬¸ ì„ë² ë”©<br/>2. ë²¡í„° ê²€ìƒ‰<br/>3. ì»¨í…ìŠ¤íŠ¸ ìƒì„±<br/>4. ë‹µë³€ ìƒì„±"]
        ChatOutput["ì±—ë´‡ ë‹µë³€"]
        
        ChatInput --> ChatRAG
        ChatRAG --> ChatOutput
        ChatRAG -.->|ì„ë² ë”©| Embedder
        ChatRAG -.->|GPU ì¶”ë¡ | LLMServer
    end

    subgraph Model3["ğŸ¯ Model 3: ê°œì¸í™” ì¶”ì²œ (LangGraph)"]
        DataInput["ğŸ“¥ ì…ë ¥ ë°ì´í„°<br/>ì„¤ë¬¸ì¡°ì‚¬/ì‚¬ì „í‰ê°€"]
        LG1["Node 1:<br/>ë°ì´í„° ê²€ì¦"]
        LG2["Node 2:<br/>ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±"]
        LG3["Node 3:<br/>í˜‘ì—… í•„í„°ë§"]
        LG4["Node 4:<br/>ê²°ê³¼ ìƒì„±"]
        NCF["Neural Collaborative<br/>Filtering Model<br/>âš ï¸ Cold Start ë¬¸ì œ"]
        
        DataInput --> LG1
        LG1 --> LG2
        LG2 --> LG3
        LG3 --> LG4
        LG3 -.->|AI ëª¨ë¸ í˜¸ì¶œ| NCF
        NCF -.->|ê²°ê³¼ ë°˜í™˜| LG4
    end

    subgraph Data["ğŸ’¾ Data Layer"]
        MySQLInput["MySQL ì…ë ¥ í…Œì´ë¸”<br/>- ì„¤ë¬¸ì¡°ì‚¬ ë°ì´í„°<br/>- ì‚¬ì „í‰ê°€ ë°ì´í„°<br/>- ë¬¸ì œ ë©”íƒ€ë°ì´í„°"]
        MySQLOutput["MySQL ì¶œë ¥ í…Œì´ë¸”<br/>- ê°œì¸í™” ê²°ê³¼<br/>- ì¶”ì²œ ë°ì´í„°<br/>- ì‚¬ìš©ì ì œì¶œ ì½”ë“œ"]
        Redis["Redis<br/>- API ì‘ë‹µ ìºì‹±<br/>- ì„¸ì…˜ ê´€ë¦¬"]
        ProblemVectorDB["ChromaDB Collection 1<br/>ë°±ì¤€ ë¬¸ì œ ë²¡í„°<br/>(6,000+ ë¬¸ì œ)"]
        ChatVectorDB["ChromaDB Collection 2<br/>ì±—ë´‡ ì§€ì‹ ë²¡í„°"]
    end

    subgraph Infra["â˜ï¸ Infrastructure Layer"]
        RunPod["RunPod GPU<br/>RTX 4090 24GB<br/>vLLM ì„œë²„ í˜¸ìŠ¤íŒ…"]
        AWS["AWS Lightsail/EC2<br/>Django + React ë°°í¬"]
        GitHub["GitHub<br/>ì½”ë“œ ê´€ë¦¬ + CI/CD"]
    end

    CodeEditor -->|íŒíŠ¸ ìš”ì²­| React
    Survey -->|ì…ë ¥| React
    React -->|API ìš”ì²­| Nginx
    Nginx -->|ë¼ìš°íŒ…| DjangoAPI
    DjangoAPI -->|ì¸ì¦| JWT
    
    DjangoAPI -->|íŒíŠ¸ ìƒì„± ìš”ì²­| HintInput
    HintOutput -->|íŒíŠ¸ ë°˜í™˜| React
    React -->|íŒíŠ¸ í‘œì‹œ| CodeEditor
    
    DjangoAPI -->|ì±—ë´‡ ì§ˆë¬¸| ChatInput
    ChatOutput -->|ë‹µë³€ ë°˜í™˜| React
    
    DjangoAPI -->|ì„¤ë¬¸ë°ì´í„° ì €ì¥| MySQLInput
    MySQLInput -->|ë°ì´í„° ì¡°íšŒ| DjangoAPI
    DjangoAPI -->|Model 3 ìš”ì²­| DataInput
    
    DataInput -->|LangGraph<br/>ì›Œí¬í”Œë¡œìš°| LG1
    LG4 -->|ê²°ê³¼ ë°˜í™˜| DjangoAPI
    DjangoAPI -->|ê²°ê³¼ ì €ì¥| MySQLOutput
    
    Step1 -->|ë¬¸ì œ ì •ë³´ ì¡°íšŒ| MySQLInput
    Step2 -->|ë²¡í„° ê²€ìƒ‰| ProblemVectorDB
    ChatRAG -->|ë²¡í„° ê²€ìƒ‰| ChatVectorDB
    
    LLMServer -->|GPU ì¶”ë¡ | RunPod
    Embedder -->|ì„ë² ë”© ìƒì„±| ProblemVectorDB
    Embedder -->|ì„ë² ë”© ìƒì„±| ChatVectorDB
    NCF -->|í•™ìŠµ/ì¶”ë¡ | RunPod
    
    DjangoAPI -->|ìºì‹±| Redis
    
    DjangoAPI -->|ë°°í¬| AWS
    React -->|ë°°í¬| AWS
    DjangoAPI -->|ì½”ë“œ ê´€ë¦¬| GitHub
    
    MySQLOutput -->|ì„œë¹„ìŠ¤ ì œê³µ| React
    
    style Frontend fill:#e1f5ff
    style Backend fill:#f3e5f5
    style Model1 fill:#fff3e0,stroke:#ff9800,stroke-width:3px
    style RAGPipeline fill:#ffe0b2
    style Model2 fill:#fff3e0
    style Model3 fill:#ffebee,stroke:#f44336,stroke-width:2px
    style Data fill:#e8f5e9
    style Infra fill:#fce4ec
    style DataInput fill:#ffccbc
    style LG1 fill:#ffccbc
    style LG2 fill:#ffccbc
    style LG3 fill:#ffccbc
    style LG4 fill:#ffccbc
    style NCF fill:#ef5350
    style HintInput fill:#fff3e0
    style Step1 fill:#ffcc80
    style Step2 fill:#ffcc80
    style Step3 fill:#ffcc80
    style Step4 fill:#ffcc80
    style HintOutput fill:#fff3e0
```

---

### ì œì•ˆ ì•„í‚¤í…ì²˜ (Hybrid: Content + Bandit + LLM)

```mermaid
graph TB
    subgraph Frontend["ğŸ¨ Frontend Layer"]
        React["React Web Application<br/>Monaco Editor í†µí•©"]
        Survey["ğŸ“ ì„¤ë¬¸ì¡°ì‚¬<br/>ì‚¬ì „í‰ê°€ ì…ë ¥"]
        CodeEditor["ğŸ’» ì½”ë“œ ì‹¤ìŠµì°½<br/>ì‹¤ì‹œê°„ íŒíŠ¸ ìš”ì²­"]
    end

    subgraph Backend["ğŸ”§ Backend Layer"]
        DjangoAPI["Django REST API"]
        JWT["JWT ì¸ì¦"]
        Nginx["Nginx Reverse Proxy"]
        LangGraphEngine["LangGraph<br/>ì›Œí¬í”Œë¡œìš° ì—”ì§„"]
    end

    subgraph Model1["ğŸ¤– Model 1: AI ì½”ë“œ íŒíŠ¸ (RAG ê¸°ë°˜)"]
        HintInput["íŒíŠ¸ ìš”ì²­<br/>(ë¬¸ì œë²ˆí˜¸ + ì‚¬ìš©ì ì½”ë“œ)"]
        
        subgraph RAGPipeline["RAG íŒŒì´í”„ë¼ì¸"]
            Step1["1. ë¬¸ì œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ<br/>(MySQL)"]
            Step2["2. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰<br/>(ChromaDB)"]
            Step3["3. í”„ë¡¬í”„íŠ¸ ìƒì„±<br/>(ë¬¸ì œ+ì½”ë“œ+ìœ ì‚¬ì˜ˆì œ)"]
            Step4["4. LLM ì¶”ë¡ <br/>(Qwen2.5-Coder-7B)"]
            
            Step1 --> Step2
            Step2 --> Step3
            Step3 --> Step4
        end
        
        HintInput --> Step1
        Step4 --> HintOutput["íŒíŠ¸ ì¶œë ¥<br/>(ë‹¨ê³„ë³„ ì„¤ëª…)"]
    end

    subgraph Model2["ğŸ¤– Model 2: RAG ì±—ë´‡"]
        ChatInput["ì‚¬ìš©ì ì§ˆë¬¸"]
        ChatRAG["1. ì§ˆë¬¸ ì„ë² ë”©<br/>2. ë²¡í„° ê²€ìƒ‰<br/>3. ì»¨í…ìŠ¤íŠ¸ ìƒì„±<br/>4. ë‹µë³€ ìƒì„±"]
        ChatOutput["ì±—ë´‡ ë‹µë³€"]
        
        ChatInput --> ChatRAG
        ChatRAG --> ChatOutput
    end

    subgraph Model3["ğŸ¯ Model 3: Hybrid ê°œì¸í™” (LangGraph)"]
        DataInput["ğŸ“¥ ì…ë ¥ ë°ì´í„°<br/>ì„¤ë¬¸ì¡°ì‚¬/ì‚¬ì „í‰ê°€"]
        LG1["Node 1:<br/>ë°ì´í„° ê²€ì¦"]
        LG2["Node 2:<br/>ì‚¬ìš©ì í”„ë¡œí•„<br/>ì„ë² ë”© ìƒì„±"]
        
        subgraph Stage1["âœ… Stage 1: Content-Based"]
            LG3_1["Node 3-1:<br/>ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰<br/>(ChromaDB)"]
            Candidates50["í›„ë³´ 50ê°œ ì¶”ì¶œ<br/>0.1ì´ˆ"]
        end
        
        subgraph Stage2["âœ… Stage 2: Thompson Sampling"]
            LG3_2["Node 3-2:<br/>Bandit ì„ ë³„<br/>(NumPy)"]
            Candidates10["í›„ë³´ 10ê°œ ì„ ë³„<br/>0.01ì´ˆ"]
        end
        
        subgraph Stage3["âœ… Stage 3: LLM Re-ranking"]
            LG3_3["Node 3-3:<br/>LLM Few-Shot<br/>(vLLM)"]
            Final5["ìµœì¢… 5ê°œ + ì¶”ì²œ ì´ìœ <br/>1-2ì´ˆ"]
        end
        
        LG4["Node 4:<br/>ê²°ê³¼ ìƒì„±<br/>+ ìºì‹±"]
        
        DataInput --> LG1
        LG1 --> LG2
        LG2 --> LG3_1
        LG3_1 --> Candidates50
        Candidates50 --> LG3_2
        LG3_2 --> Candidates10
        Candidates10 --> LG3_3
        LG3_3 --> Final5
        Final5 --> LG4
    end

    subgraph SharedInfra["ğŸ”— ê³µìœ  AI ì¸í”„ë¼"]
        VLLMServer["vLLM ì„œë²„<br/>Qwen2.5-Coder-7B-Instruct<br/>8ë¹„íŠ¸ ì–‘ìí™”<br/>ë‹¨ì¼ GPU ê³µìœ "]
        EmbeddingModel["jhgan/ko-sroberta-multitask<br/>ì„ë² ë”© ëª¨ë¸<br/>CPU ì¶”ë¡ "]
    end

    subgraph Data["ğŸ’¾ Data Layer"]
        MySQLInput["MySQL ì…ë ¥ í…Œì´ë¸”<br/>- ì„¤ë¬¸ì¡°ì‚¬ ë°ì´í„°<br/>- ì‚¬ì „í‰ê°€ ë°ì´í„°<br/>- ë¬¸ì œ ë©”íƒ€ë°ì´í„°<br/>- ì‚¬ìš©ì ì œì¶œ ì½”ë“œ"]
        MySQLOutput["MySQL ì¶œë ¥ í…Œì´ë¸”<br/>- ê°œì¸í™” ê²°ê³¼<br/>- ì¶”ì²œ ë°ì´í„°<br/>- ì‚¬ìš©ì í–‰ë™ ë¡œê·¸<br/>- Bandit í•™ìŠµ ë°ì´í„°"]
        Redis["Redis<br/>- ì¶”ì²œ ê²°ê³¼ ìºì‹±<br/>- Bandit ìƒíƒœ ì €ì¥<br/>- ì„¸ì…˜ ê´€ë¦¬"]
        
        subgraph ChromaDBCollections["ChromaDB (í†µí•© ë²¡í„° DB)"]
            ProblemVectors["Collection 1:<br/>ë°±ì¤€ ë¬¸ì œ ë²¡í„°<br/>(6,000+ ë¬¸ì œ)"]
            ChatVectors["Collection 2:<br/>ì±—ë´‡ ì§€ì‹ ë²¡í„°"]
            ContentVectors["Collection 3:<br/>í•™ìŠµ ì½˜í…ì¸  ë²¡í„°<br/>(ê°œì¸í™”ìš©)"]
            UserVectors["Collection 4:<br/>ì‚¬ìš©ì í”„ë¡œí•„ ë²¡í„°"]
        end
    end

    subgraph Infra["â˜ï¸ Infrastructure Layer"]
        RunPod["RunPod GPU<br/>RTX 4090 24GB<br/>vLLM ë‹¨ì¼ ì„œë²„<br/>ì „ ëª¨ë¸ ê³µìœ "]
        AWS["AWS Lightsail/EC2<br/>Django + React ë°°í¬"]
        GitHub["GitHub<br/>ì½”ë“œ ê´€ë¦¬ + CI/CD"]
    end

    CodeEditor -->|íŒíŠ¸ ìš”ì²­| React
    Survey -->|ì…ë ¥| React
    React -->|API ìš”ì²­| Nginx
    Nginx -->|ë¼ìš°íŒ…| DjangoAPI
    DjangoAPI -->|ì¸ì¦| JWT
    
    DjangoAPI -->|íŒíŠ¸ ìƒì„± ìš”ì²­| HintInput
    HintOutput -->|íŒíŠ¸ ë°˜í™˜| React
    React -->|íŒíŠ¸ í‘œì‹œ| CodeEditor
    
    DjangoAPI -->|ì±—ë´‡ ì§ˆë¬¸| ChatInput
    ChatOutput -->|ë‹µë³€ ë°˜í™˜| React
    
    DjangoAPI -->|ì„¤ë¬¸ë°ì´í„° ì €ì¥| MySQLInput
    MySQLInput -->|ë°ì´í„° ì¡°íšŒ| DjangoAPI
    DjangoAPI -->|Model 3 ìš”ì²­| DataInput
    
    DataInput -->|LangGraph ì‹¤í–‰| LangGraphEngine
    LangGraphEngine -->|ì›Œí¬í”Œë¡œìš°| LG1
    LG4 -->|ê²°ê³¼ ë°˜í™˜| DjangoAPI
    DjangoAPI -->|ê²°ê³¼ ì €ì¥| MySQLOutput
    
    Step1 -->|ë¬¸ì œ ì •ë³´ ì¡°íšŒ| MySQLInput
    Step2 -->|ë²¡í„° ê²€ìƒ‰| ProblemVectors
    Step4 -->|LLM ì¶”ë¡ | VLLMServer
    
    ChatRAG -->|ì„ë² ë”© ìƒì„±| EmbeddingModel
    ChatRAG -->|ë²¡í„° ê²€ìƒ‰| ChatVectors
    ChatRAG -->|LLM ì¶”ë¡ | VLLMServer
    
    LG2 -->|ì„ë² ë”© ìƒì„±| EmbeddingModel
    LG3_1 -->|ë²¡í„° ê²€ìƒ‰| ContentVectors
    LG3_1 -->|ì‚¬ìš©ì ë²¡í„°| UserVectors
    LG3_2 -->|Bandit ìƒíƒœ| Redis
    LG3_3 -->|LLM ì¶”ë¡ | VLLMServer
    LG4 -->|ìºì‹±| Redis
    
    EmbeddingModel -->|ë²¡í„° ìƒì„±| ProblemVectors
    EmbeddingModel -->|ë²¡í„° ìƒì„±| ChatVectors
    EmbeddingModel -->|ë²¡í„° ìƒì„±| ContentVectors
    EmbeddingModel -->|ë²¡í„° ìƒì„±| UserVectors
    
    VLLMServer -->|GPU ì¶”ë¡ | RunPod
    
    DjangoAPI -->|ìºì‹±| Redis
    
    DjangoAPI -->|ë°°í¬| AWS
    React -->|ë°°í¬| AWS
    DjangoAPI -->|ì½”ë“œ ê´€ë¦¬| GitHub
    
    MySQLOutput -->|ì„œë¹„ìŠ¤ ì œê³µ| React
    React -->|í–‰ë™ ë°ì´í„°| MySQLOutput
    
    style Frontend fill:#e1f5ff
    style Backend fill:#f3e5f5
    style Model1 fill:#fff3e0,stroke:#ff9800,stroke-width:3px
    style RAGPipeline fill:#ffe0b2
    style Model2 fill:#fff3e0
    style Model3 fill:#c8e6c9,stroke:#4caf50,stroke-width:4px
    style Stage1 fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style Stage2 fill:#fff9c4,stroke:#fbc02d,stroke-width:2px
    style Stage3 fill:#ffe0b2,stroke:#ff9800,stroke-width:2px
    style SharedInfra fill:#e3f2fd,stroke:#2196f3,stroke-width:3px
    style Data fill:#e8f5e9
    style ChromaDBCollections fill:#c8e6c9
    style Infra fill:#fce4ec
    style DataInput fill:#a5d6a7
    style LG1 fill:#a5d6a7
    style LG2 fill:#a5d6a7
    style LG3_1 fill:#c5e1a5
    style LG3_2 fill:#fff59d
    style LG3_3 fill:#ffcc80
    style LG4 fill:#a5d6a7
    style Candidates50 fill:#dcedc8
    style Candidates10 fill:#fff9c4
    style Final5 fill:#ffe0b2
    style HintInput fill:#fff3e0
    style Step1 fill:#ffcc80
    style Step2 fill:#ffcc80
    style Step3 fill:#ffcc80
    style Step4 fill:#ffcc80
    style HintOutput fill:#fff3e0
    style VLLMServer fill:#bbdefb
    style EmbeddingModel fill:#bbdefb
```

---

### ì•„í‚¤í…ì²˜ ë¹„êµ

| êµ¬ì„± ìš”ì†Œ | í˜„ì¬ (NCF) | ì œì•ˆ (Hybrid) | ê°œì„  íš¨ê³¼ |
|----------|-----------|--------------|----------|
| **AI íŒíŠ¸ ëª¨ë¸** | Qwen2.5-Coder-7B RAG | Qwen2.5-Coder-7B RAG (ë™ì¼) | ë³€ê²½ ì—†ìŒ, ì•ˆì •ì„± ìœ ì§€ |
| **íŒíŠ¸ ìƒì„± í”„ë¡œì„¸ìŠ¤** | 4ë‹¨ê³„ RAG íŒŒì´í”„ë¼ì¸ | 4ë‹¨ê³„ RAG íŒŒì´í”„ë¼ì¸ (ë™ì¼) | ë³€ê²½ ì—†ìŒ |
| **vLLM ì„œë²„** | ë‹¨ì¼ GPU ì „ìš© | 3ê°œ ëª¨ë¸ ê³µìœ  (íŒíŠ¸+ì±—ë´‡+ì¶”ì²œ) | GPU ë¹„ìš© 57%â†“ |
| **ChromaDB** | 2ê°œ Collection (ë¬¸ì œ+ì±—ë´‡) | 4ê°œ Collection (ë¬¸ì œ+ì±—ë´‡+ì½˜í…ì¸ +ì‚¬ìš©ì) | í†µí•© ê´€ë¦¬, íš¨ìœ¨â†‘ |
| **ê°œì¸í™” Node 3** | ë‹¨ì¼ NCF ëª¨ë¸ | 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ | ëª¨ë“ˆí™”, ìœ ì§€ë³´ìˆ˜ì„±â†‘ |
| **Cold Start** | âŒ ì–´ë ¤ì›€ | âœ… ì¦‰ì‹œ ëŒ€ì‘ | ì‹ ê·œ ì‚¬ìš©ì ë§Œì¡±ë„â†‘ |
| **ì¶”ë¡  ì†ë„** | ~3ì´ˆ | 0.1~1.2ì´ˆ (ìºì‹± ì‹œ 0.5ì´ˆ) | 4-6ë°° ë¹ ë¦„ |
| **ì¸í”„ë¼ ì¬ì‚¬ìš©** | âŒ NCF ë³„ë„ í•™ìŠµ | âœ… vLLM+ChromaDB 100% ì¬ì‚¬ìš© | ë¹„ìš© 93%â†“ |
| **ì„¤ëª… ê°€ëŠ¥ì„±** | â­ ë‚®ìŒ | â­â­â­â­â­ ìì—°ì–´ ì„¤ëª… | UX ëŒ€í­ ê°œì„  |
| **ê°œë°œ ì‹œê°„** | 2-3ê°œì›” | 1ê°œì›” | 70% ë‹¨ì¶• |
| **GPU ì˜ì¡´ì„±** | RunPod í•„ìˆ˜ (NCF í•™ìŠµ) | vLLM ê³µìœ  (ì„ íƒ) | ë¹„ìš© íš¨ìœ¨â†‘ |
| **ë°ì´í„° ìš”êµ¬ëŸ‰** | ìˆ˜ì²œ ê°œ ìƒí˜¸ì‘ìš© | ì„¤ë¬¸ì¡°ì‚¬ë§Œ | ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥ |
| **ì‹¤ì‹œê°„ í•™ìŠµ** | âŒ ì£¼ê¸°ì  ì¬í•™ìŠµ | âœ… Bandit ì¦‰ì‹œ ë°˜ì˜ | ê°œì¸í™” ì†ë„â†‘ |
| **Redis í™œìš©** | API ìºì‹±ë§Œ | ìºì‹± + Bandit ìƒíƒœ + ì„¸ì…˜ | ë‹¤ëª©ì  í™œìš© |
| **LangGraph í†µí•©** | 4 Nodes (ë‹¨ìˆœ) | 7 Nodes (3ë‹¨ê³„ ë¶„ë¦¬) | ì›Œí¬í”Œë¡œìš° ëª…í™•í™” |

---

### ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡œë“œë§µ

```mermaid
gantt
    title Hybrid ê°œì¸í™” ì‹œìŠ¤í…œ ë§ˆì´ê·¸ë ˆì´ì…˜
    dateFormat  YYYY-MM-DD
    section Phase 1
    Content-Based êµ¬í˜„           :a1, 2025-01-01, 7d
    ChromaDB ì½˜í…ì¸  ë“±ë¡         :a2, after a1, 3d
    LangGraph Node 3-1 í†µí•©      :a3, after a2, 3d
    í…ŒìŠ¤íŠ¸ ë° ê²€ì¦               :a4, after a3, 2d
    
    section Phase 2
    Thompson Sampling êµ¬í˜„        :b1, after a4, 5d
    ì‚¬ìš©ì í–‰ë™ ë¡œê¹… ì¶”ê°€         :b2, after b1, 3d
    LangGraph Node 3-2 í†µí•©       :b3, after b2, 2d
    
    section Phase 3
    LLM Re-ranking í”„ë¡¬í”„íŠ¸ ì„¤ê³„  :c1, after b3, 3d
    vLLM ì„œë²„ í†µí•©               :c2, after c1, 2d
    LangGraph Node 3-3 í†µí•©       :c3, after c2, 3d
    
    section Phase 4
    Redis ìºì‹± êµ¬í˜„              :d1, after c3, 2d
    ì„±ëŠ¥ ìµœì í™”                  :d2, after d1, 3d
    A/B í…ŒìŠ¤íŠ¸                   :d3, after d2, 7d
    NCF ë‹¨ê³„ì  ì œê±°              :d4, after d3, 3d
```

**ì´ ì†Œìš” ê¸°ê°„**: ì•½ 4-5ì£¼  
**í˜„ì¬ NCF ìœ ì§€**: Phase 4 A/B í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì „ê¹Œì§€ ë³‘í–‰ ìš´ì˜

---

## ğŸ”§ í†µí•© ê¸°ìˆ  ìŠ¤íƒ (í˜„ì¬ â†’ ì œì•ˆ)

### í˜„ì¬ ê¸°ìˆ  ìŠ¤íƒ

```mermaid
flowchart LR
    subgraph User["ğŸ‘¤ ì‚¬ìš©ì ì¸í„°ë™ì…˜"]
        U1["ì½”ë“œ ì‘ì„±/ì‹¤ìŠµ"]
        U2["ì±—ë´‡ ì§ˆë¬¸"]
        U3["ì¶”ì²œ ìš”ì²­"]
    end

    subgraph FE["ğŸ¨ í”„ë¡ íŠ¸ì—”ë“œ<br/><i>React + Monaco Editor</i>"]
        FE1["UI ë Œë”ë§"]
        FE2["ì‹¤ìŠµì°½ ì œê³µ"]
        FE3["ê²°ê³¼ ì‹œê°í™”"]
    end

    subgraph BE["ğŸ”§ ë°±ì—”ë“œ<br/><i>Django REST + JWT + Nginx</i>"]
        BE1["ìš”ì²­ ë¼ìš°íŒ…"]
        BE2["ì¸ì¦/ê¶Œí•œ"]
        BE3["ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§"]
    end

    subgraph Models["ğŸ¤– AI ëª¨ë¸ (í˜„ì¬)"]
        M1["Qwen2.5-Coder-7B<br/>(ì½”ë“œ íŒíŠ¸ RAG)<br/>4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸"]
        M2["jhgan/ko-sroberta<br/>(ì„ë² ë”©)<br/>+ ChromaDB"]
        M3["NCF<br/>(ê°œì¸í™” ì¶”ì²œ)<br/>âš ï¸ Cold Start ë¬¸ì œ"]
    end

    subgraph Data["ğŸ’¾ ë°ì´í„° ê³„ì¸µ"]
        VDB["ChromaDB<br/>(ë²¡í„° ê²€ìƒ‰)"]
        DB["MySQL<br/>(ì‚¬ìš©ì/ì„¤ë¬¸/ë¡œê·¸)"]
        Cache["Redis<br/>(ìºì‹±)"]
    end

    subgraph Infra["â˜ï¸ ì¸í”„ë¼<br/><i>RunPod + AWS + Github</i>"]
        GPU["RunPod GPU<br/>(ëª¨ë¸ ì¶”ë¡ )"]
        Deploy["AWS Lightsail/EC2<br/>(ì›¹ ì„œë¹„ìŠ¤)"]
        Version["GitHub<br/>(ì½”ë“œ ê´€ë¦¬)"]
    end

    U1 --> FE2
    U2 --> FE1
    U3 --> FE1
    
    FE1 --> BE1
    FE2 --> BE1
    FE3 --> BE1
    
    BE1 --> BE2
    BE2 --> BE3
    
    BE3 --> M1
    BE3 --> M2
    BE3 --> M3
    
    M1 --> GPU
    M2 --> VDB
    M3 --> GPU
    
    VDB --> M2
    DB --> BE3
    Cache --> BE3
    
    M1 --> BE3
    M2 --> BE3
    M3 --> BE3
    
    BE3 --> FE3
    FE3 --> U1
    FE3 --> U2
    FE3 --> U3

    style User fill:#bbdefb
    style FE fill:#e3f2fd
    style BE fill:#f3e5f5
    style Models fill:#ffccbc,stroke:#ff9800,stroke-width:2px
    style Data fill:#e8f5e9
    style Infra fill:#fce4ec
    style M3 fill:#ffebee,stroke:#f44336,stroke-width:2px
```

---

### ì œì•ˆ ê¸°ìˆ  ìŠ¤íƒ (Hybrid ê°œì¸í™”)

```mermaid
flowchart LR
    subgraph User["ğŸ‘¤ ì‚¬ìš©ì ì¸í„°ë™ì…˜"]
        U1["ì½”ë“œ ì‘ì„±/ì‹¤ìŠµ"]
        U2["ì±—ë´‡ ì§ˆë¬¸"]
        U3["í•™ìŠµ ì¶”ì²œ ìš”ì²­"]
    end

    subgraph FE["ğŸ¨ í”„ë¡ íŠ¸ì—”ë“œ<br/><i>React + Monaco Editor</i>"]
        FE1["UI ë Œë”ë§"]
        FE2["ì‹¤ìŠµì°½ ì œê³µ"]
        FE3["ê²°ê³¼ ì‹œê°í™”<br/>+ ì¶”ì²œ ì´ìœ  í‘œì‹œ"]
    end

    subgraph BE["ğŸ”§ ë°±ì—”ë“œ<br/><i>Django REST + JWT + Nginx</i>"]
        BE1["ìš”ì²­ ë¼ìš°íŒ…"]
        BE2["ì¸ì¦/ê¶Œí•œ"]
        BE3["ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§"]
        BE4["LangGraph<br/>ì›Œí¬í”Œë¡œìš° ì—”ì§„"]
    end

    subgraph Models["ğŸ¤– AI ëª¨ë¸ (ê°œì„ )"]
        M1["Qwen2.5-Coder-7B<br/>vLLM ì„œë²„<br/>(ì½”ë“œ íŒíŠ¸ RAG)<br/>4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸"]
        M2["jhgan/ko-sroberta<br/>(ì„ë² ë”©)<br/>+ ChromaDB"]
        
        subgraph M3["ğŸ¯ Hybrid ê°œì¸í™”<br/>(LangGraph 3ë‹¨ê³„)"]
            M3_1["Stage 1:<br/>Content-Based<br/>(ChromaDB ì¬ì‚¬ìš©)"]
            M3_2["Stage 2:<br/>Thompson Sampling<br/>(NumPy)"]
            M3_3["Stage 3:<br/>LLM Re-ranking<br/>(vLLM ì¬ì‚¬ìš©)"]
        end
    end

    subgraph Data["ğŸ’¾ ë°ì´í„° ê³„ì¸µ"]
        VDB["ChromaDB<br/>- RAG ë²¡í„°<br/>- ì½˜í…ì¸  ë²¡í„°<br/>- ì‚¬ìš©ì ë²¡í„°"]
        DB["MySQL<br/>- ì‚¬ìš©ì ì •ë³´<br/>- ì„¤ë¬¸ì¡°ì‚¬<br/>- ì‚¬ì „í‰ê°€<br/>- í–‰ë™ ë¡œê·¸"]
        Cache["Redis<br/>- ì¶”ì²œ ìºì‹±<br/>- Bandit ìƒíƒœ"]
    end

    subgraph Infra["â˜ï¸ ì¸í”„ë¼<br/><i>RunPod + AWS + Github</i>"]
        GPU["RunPod GPU<br/>(vLLM ê³µìœ  ì„œë²„)"]
        Deploy["AWS Lightsail/EC2<br/>(ì›¹ ì„œë¹„ìŠ¤)"]
        Version["GitHub<br/>(ì½”ë“œ ê´€ë¦¬)"]
    end

    U1 --> FE2
    U2 --> FE1
    U3 --> FE1
    
    FE1 --> BE1
    FE2 --> BE1
    FE3 --> BE1
    
    BE1 --> BE2
    BE2 --> BE3
    BE3 --> BE4
    
    BE4 --> M1
    BE4 --> M2
    BE4 --> M3_1
    
    M3_1 --> M3_2
    M3_2 --> M3_3
    
    M1 --> GPU
    M3_3 --> GPU
    
    M2 --> VDB
    M3_1 --> VDB
    M3_2 --> Cache
    M3_3 --> Cache
    
    VDB --> M2
    VDB --> M3_1
    DB --> BE4
    Cache --> BE4
    
    M1 --> BE4
    M2 --> BE4
    M3_3 --> BE4
    
    BE4 --> BE3
    BE3 --> FE3
    FE3 --> U1
    FE3 --> U2
    FE3 --> U3
    
    U1 -.->|í–‰ë™ ë¡œê·¸| DB
    U2 -.->|í–‰ë™ ë¡œê·¸| DB
    U3 -.->|í–‰ë™ ë¡œê·¸| DB

    style User fill:#bbdefb
    style FE fill:#e3f2fd
    style BE fill:#f3e5f5
    style Models fill:#c8e6c9,stroke:#4caf50,stroke-width:3px
    style M3 fill:#a5d6a7,stroke:#4caf50,stroke-width:2px
    style M3_1 fill:#c5e1a5
    style M3_2 fill:#fff59d
    style M3_3 fill:#ffcc80
    style Data fill:#e8f5e9
    style Infra fill:#fce4ec
```

---

### ê¸°ìˆ  ìŠ¤íƒ ë¹„êµ ìƒì„¸

| ê³„ì¸µ | í•­ëª© | í˜„ì¬ | ì œì•ˆ | ë³€ê²½ ì´ìœ  |
|------|------|------|------|----------|
| **í”„ë¡ íŠ¸ì—”ë“œ** | í”„ë ˆì„ì›Œí¬ | React + Monaco | React + Monaco | ë³€ê²½ ì—†ìŒ |
| | ì¶”ê°€ ê¸°ëŠ¥ | - | ì¶”ì²œ ì´ìœ  í‘œì‹œ | UX ê°œì„  |
| **ë°±ì—”ë“œ** | API | Django REST | Django REST | ë³€ê²½ ì—†ìŒ |
| | ì›Œí¬í”Œë¡œìš° | - | LangGraph | ê°œì¸í™” ë¡œì§ ëª¨ë“ˆí™” |
| | ì¸ì¦ | JWT | JWT | ë³€ê²½ ì—†ìŒ |
| | í”„ë¡ì‹œ | Nginx | Nginx | ë³€ê²½ ì—†ìŒ |
| **AI ëª¨ë¸** | ì½”ë“œ íŒíŠ¸ | Qwen2.5-Coder-7B RAG (4ë‹¨ê³„) | Qwen2.5-Coder-7B RAG (4ë‹¨ê³„) | ë³€ê²½ ì—†ìŒ, ì•ˆì •ì  |
| | RAG ì±—ë´‡ | jhgan/ko-sroberta + ChromaDB | jhgan/ko-sroberta + ChromaDB | ë³€ê²½ ì—†ìŒ |
| | ê°œì¸í™” | NCF (ë‹¨ì¼ ëª¨ë¸) | **Hybrid 3ë‹¨ê³„** | Cold Start í•´ê²° |
| | ã„´ Stage 1 | - | Content-Based (ChromaDB) | ì„ë² ë”© ìœ ì‚¬ë„ |
| | ã„´ Stage 2 | - | Thompson Sampling | ì‹¤ì‹œê°„ í•™ìŠµ |
| | ã„´ Stage 3 | - | LLM Few-Shot (vLLM) | ìì—°ì–´ ì„¤ëª… |
| **ë°ì´í„°** | ë²¡í„° DB | ChromaDB (ë¬¸ì œ 6K + ì±—ë´‡) | ChromaDB (ë¬¸ì œ + ì±—ë´‡ + ì½˜í…ì¸  + ì‚¬ìš©ì) | Collection í™•ì¥ |
| | RDBMS | MySQL (ì„¤ë¬¸ + í‰ê°€ + ë¬¸ì œ) | MySQL (ì„¤ë¬¸ + í‰ê°€ + ë¬¸ì œ + í–‰ë™ë¡œê·¸) | í–‰ë™ ì¶”ì  ì¶”ê°€ |
| | ìºì‹± | Redis (API ìºì‹±) | Redis (API + ì¶”ì²œ + Bandit) | ë‹¤ëª©ì  í™œìš© |
| **ì¸í”„ë¼** | GPU | RunPod vLLM (ë‹¨ì¼ ì„œë²„) | RunPod vLLM (3ëª¨ë¸ ê³µìœ ) | ê³µìœ ë¡œ ë¹„ìš© íš¨ìœ¨â†‘ |
| | ë°°í¬ | AWS Lightsail/EC2 | AWS Lightsail/EC2 | ë³€ê²½ ì—†ìŒ |
| | CI/CD | GitHub | GitHub | ë³€ê²½ ì—†ìŒ |

---

### ì£¼ìš” ê°œì„  í¬ì¸íŠ¸

#### 1ï¸âƒ£ ëª¨ë¸ í†µí•© (ë¹„ìš© ì ˆê°)
**í˜„ì¬**: vLLM ì„œë²„ê°€ ì½”ë“œ íŒíŠ¸ + ì±—ë´‡ë§Œ ë‹´ë‹¹  
**ì œì•ˆ**: vLLM ì„œë²„ê°€ ì½”ë“œ íŒíŠ¸ + ì±—ë´‡ + LLM Re-rankingê¹Œì§€ ë‹´ë‹¹ (Hybrid Stage 3)

ğŸ’° **ë¹„ìš©**: NCF ë³„ë„ í•™ìŠµ ë¹„ìš© ì œê±° â†’ $70/ì›” â†’ $5/ì›” (93% ì ˆê°)

#### 2ï¸âƒ£ ì¸í”„ë¼ ì¬ì‚¬ìš© (ê°œë°œ ì‹œê°„ ë‹¨ì¶•)
**í˜„ì¬**: ChromaDBëŠ” ë¬¸ì œ ë²¡í„° + ì±—ë´‡ ì§€ì‹ë§Œ ì €ì¥  
**ì œì•ˆ**: ChromaDBì— í•™ìŠµ ì½˜í…ì¸  ë²¡í„° + ì‚¬ìš©ì í”„ë¡œí•„ ë²¡í„° ì¶”ê°€ (Collection 2ê°œ â†’ 4ê°œ)

â±ï¸ **ê°œë°œ ì‹œê°„**: ì‹ ê·œ ë²¡í„° DB êµ¬ì¶• ë¶ˆí•„ìš” â†’ 1ì£¼ ì ˆì•½

#### 3ï¸âƒ£ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ê°•í™”
**í˜„ì¬**: ì‚¬ìš©ì í–‰ë™ â†’ MySQL ì €ì¥ë§Œ  
**ì œì•ˆ**: ì‚¬ìš©ì í–‰ë™ â†’ Bandit ì‹¤ì‹œê°„ í•™ìŠµ + Redis ìƒíƒœ ì €ì¥ + MySQL ë¡œê¹…

ğŸ“ˆ **ì¶”ì²œ í’ˆì§ˆ**: ì •ì  â†’ ë™ì  ê°œì¸í™” (ì‹¤ì‹œê°„ í•™ìŠµ)

#### 4ï¸âƒ£ LangGraph ë„ì… (ìœ ì§€ë³´ìˆ˜ì„±)
**í˜„ì¬**: Django ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì— AI í˜¸ì¶œ í•˜ë“œì½”ë”©  
**ì œì•ˆ**: LangGraphë¡œ 7-Node ì›Œí¬í”Œë¡œìš° ì‹œê°í™” + ê´€ë¦¬

ğŸ”§ **ìœ ì§€ë³´ìˆ˜**: ì½”ë“œ ê°€ë…ì„±â†‘, ë””ë²„ê¹… ìš©ì´, ë‹¨ê³„ë³„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

---

### ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œ í˜¸í™˜ì„± ë³´ì¥

```python
# Django Views - ê¸°ì¡´ API ì—”ë“œí¬ì¸íŠ¸ ìœ ì§€
@api_view(['POST'])
@permission_classes([IsAuthenticated])
def get_personalized_recommendations(request):
    """
    ê¸°ì¡´ API ìŠ¤í™ 100% í˜¸í™˜
    ë‚´ë¶€ êµ¬í˜„ë§Œ NCF â†’ Hybridë¡œ ë³€ê²½
    """
    user_id = request.user.id
    survey_data = request.data.get('survey')
    
    # ê¸°ì¡´: NCF ì§ì ‘ í˜¸ì¶œ
    # recommendations = ncf_model.predict(user_id, survey_data)
    
    # ì‹ ê·œ: LangGraph ì›Œí¬í”Œë¡œìš° í˜¸ì¶œ
    result = langgraph_app.invoke({
        "user_id": user_id,
        "user_profile": survey_data
    })
    
    # ì‘ë‹µ í¬ë§· ë™ì¼ ìœ ì§€
    return Response({
        "recommendations": result["recommendations"],
        "explanations": result.get("explanations", [])  # ì‹ ê·œ í•„ë“œ ì¶”ê°€
    })
```

**âœ… í”„ë¡ íŠ¸ì—”ë“œ ë³€ê²½ ë¶ˆí•„ìš”**: API ìŠ¤í™ ìœ ì§€  
**âœ… ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜**: NCFì™€ Hybrid ë³‘í–‰ ìš´ì˜ ê°€ëŠ¥  
**âœ… A/B í…ŒìŠ¤íŠ¸**: ì‚¬ìš©ì 50%ì”© ë¶„ë°°í•˜ì—¬ ì„±ëŠ¥ ë¹„êµ


