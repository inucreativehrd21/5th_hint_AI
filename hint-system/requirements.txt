# ============================================================================
# INSTALLATION ORDER (CRITICAL - DO NOT CHANGE!)
# ============================================================================
# 자동 설치: bash install_dependencies.sh (권장)
# 
# 수동 설치:
# 1. pip uninstall -y vllm torch gradio tomlkit  # 충돌 제거
# 2. pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu121
# 3. pip install vllm==0.6.3 --no-deps
# 4. pip install xformers psutil numpy ray
# 5. pip install airportsdata
# 6. pip install -r requirements.txt
# 
# 주의사항:
# - torch 2.4.0 CUDA 12.1 필수 (vLLM 0.6.3 호환)
# - vLLM은 --no-deps로 설치 (torch 버전 충돌 방지)
# - tomlkit은 gradio가 자동으로 0.12.0 설치
# ============================================================================

# UI Framework
gradio==4.44.0

# Core dependencies
# torch==2.4.0 는 install_dependencies.sh에서 먼저 설치됨
transformers>=4.45.0,<4.46.0
accelerate>=0.27.0,<0.35.0
sentencepiece>=0.2.0
protobuf>=4.25.0,<5.0.0

# ============================================================================
# vLLM Dependencies Fix
# ============================================================================
# vLLM은 별도 설치: pip install vllm==0.6.3
# pyairports 0.0.1 문제 해결: airportsdata 사용
# outlines가 pyairports를 요구하지만 실제로는 airportsdata로 대체 가능
airportsdata

# Quantization support
bitsandbytes==0.44.1

# tomlkit - gradio가 자동으로 적절한 버전 설치

# ============================================================================
# Model Inference Backends
# ============================================================================

# OpenAI API 호환 (vLLM 서버 클라이언트 - REQUIRED for vLLM)
# 주의: openai>=1.0.0에서 proxies 인자 제거됨, 1.3.x 사용
openai>=1.3.0,<2.0.0

# Ollama - 로컬 환경용 (선택 사항)
# ollama>=0.1.0  # Uncomment if using Ollama

# ============================================================================
# Utilities
# ============================================================================
tqdm==4.66.5
pandas==2.2.3
numpy==1.26.4

# Configuration
pyyaml==6.0.2
python-dotenv==1.0.1
requests==2.32.3
