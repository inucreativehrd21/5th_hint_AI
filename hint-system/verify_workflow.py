"""
ì›Œí¬í”Œë¡œìš° ì½”ë“œ ë ˆë²¨ ê²€ì¦ (ì˜ì¡´ì„± ì—†ì´)
"""
import re
import os


def check_file_content(filepath, checks, description):
    """íŒŒì¼ ë‚´ìš© ê²€ì¦"""
    print(f"\nğŸ“ {description}")
    print(f"   íŒŒì¼: {filepath}")
    
    if not os.path.exists(filepath):
        print(f"   âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ!")
        return False
    
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    all_passed = True
    for check_string, description, required in checks:
        count = content.count(check_string)
        if count > 0:
            print(f"   âœ… {description} (ë°œê²¬ {count}íšŒ)")
        elif required:
            print(f"   âŒ {description} - í•„ìˆ˜ í•­ëª© ëˆ„ë½!")
            all_passed = False
        else:
            print(f"   âš ï¸  {description} - ì„ íƒ í•­ëª© ì—†ìŒ")
    
    return all_passed


def main():
    print("=" * 70)
    print("ğŸ” íŒíŠ¸ ì‹œìŠ¤í…œ ì›Œí¬í”Œë¡œìš° ì „ì²´ ê²€ì¦ (ì½”ë“œ ë ˆë²¨)")
    print("=" * 70)
    
    results = []
    
    # 1. app.py ê²€ì¦
    print("\n" + "=" * 70)
    print("Step 1: app.py - ì§„ì…ì ")
    print("=" * 70)
    
    checks = [
        ('from models.model_inference import VLLMInference', 'VLLMInference ì„í¬íŠ¸', True),
        ('from models.adaptive_prompt import AdaptivePromptGenerator', 'AdaptivePromptGenerator ì„í¬íŠ¸', True),
        ('self.prompt_generator = AdaptivePromptGenerator()', 'í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™”', True),
        ('prompt = self.prompt_generator.generate_prompt(', 'generate_prompt í˜¸ì¶œ', True),
        ('student_code=user_code', 'student_code íŒŒë¼ë¯¸í„° ì „ë‹¬', True),
        ('diagnosis=diagnosis', 'diagnosis íŒŒë¼ë¯¸í„° ì „ë‹¬', True),
    ]
    
    passed = check_file_content('app.py', checks, 'app.py ê²€ì¦')
    results.append(('app.py', passed))
    
    # 2. adaptive_prompt.py ê²€ì¦
    print("\n" + "=" * 70)
    print("Step 2: models/adaptive_prompt.py - í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°")
    print("=" * 70)
    
    checks = [
        ('from models.educational_prompts import EducationalPromptEngine', 'EducationalPromptEngine ì„í¬íŠ¸', True),
        ('self.edu_engine = EducationalPromptEngine()', 'êµìœ¡ ì—”ì§„ ì´ˆê¸°í™”', True),
        ('def generate_prompt(self, problem_id: str, student_code: str,', 'generate_prompt ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜', True),
        ('print(f"[AdaptivePromptGenerator] student_code ê¸¸ì´: {len(student_code)}', 'student_code ë¡œê¹…', True),
        ('self.edu_engine.generate_novice_prompt(', 'novice í”„ë¡¬í”„íŠ¸ í˜¸ì¶œ', True),
        ('problem_info, diagnosis, weak_areas, chain_context, student_code', 'novice - 5ê°œ íŒŒë¼ë¯¸í„° ì „ë‹¬', True),
        ('self.edu_engine.generate_intermediate_prompt(', 'intermediate í”„ë¡¬í”„íŠ¸ í˜¸ì¶œ', True),
        ('self.edu_engine.generate_advanced_prompt(', 'advanced í”„ë¡¬í”„íŠ¸ í˜¸ì¶œ', True),
    ]
    
    passed = check_file_content('models/adaptive_prompt.py', checks, 'AdaptivePromptGenerator ê²€ì¦')
    results.append(('adaptive_prompt.py', passed))
    
    # 3. educational_prompts.py ê²€ì¦
    print("\n" + "=" * 70)
    print("Step 3: models/educational_prompts.py - êµìœ¡ í”„ë¡¬í”„íŠ¸ ì—”ì§„")
    print("=" * 70)
    
    checks = [
        ('def generate_novice_prompt(self, problem_info: Dict, diagnosis:', 'novice ë©”ì„œë“œ ì •ì˜', True),
        ('weak_areas: List[str], chain_context: str, student_code: str)', 'novice - student_code íŒŒë¼ë¯¸í„°', True),
        ('print(f"\\n[EducationalPromptEngine] ì´ˆê¸‰(Novice) í”„ë¡¬í”„íŠ¸ ìƒì„±")', 'novice ë¡œê¹…', True),
        ('print(f"  í•™ìƒ ì½”ë“œ ê¸¸ì´: {len(student_code)} chars")', 'student_code ê¸¸ì´ ë¡œê¹…', True),
        ('{student_code}', 'student_code f-string ì‚½ì…', True),
        ('<thinking>', 'CoT thinking ì„¹ì…˜', True),
        ('<output>', 'CoT output ì„¹ì…˜', True),
        ('1ë‹¨ê³„:', 'ë‹¨ê³„ë³„ ì‚¬ê³ ', True),
        ('ğŸ’¡', 'Novice íŒíŠ¸ ì´ëª¨ì§€', True),
        ('def generate_intermediate_prompt(self, problem_info: Dict, diagnosis:', 'intermediate ë©”ì„œë“œ ì •ì˜', True),
        ('ğŸ§ ', 'Intermediate íŒíŠ¸ ì´ëª¨ì§€', True),
        ('def generate_advanced_prompt(self, problem_info: Dict, diagnosis:', 'advanced ë©”ì„œë“œ ì •ì˜', True),
        ('ğŸ”', 'Advanced íŒíŠ¸ ì´ëª¨ì§€', True),
    ]
    
    passed = check_file_content('models/educational_prompts.py', checks, 'EducationalPromptEngine ê²€ì¦')
    results.append(('educational_prompts.py', passed))
    
    # 4. model_inference.py ê²€ì¦
    print("\n" + "=" * 70)
    print("Step 4: models/model_inference.py - vLLM ì¶”ë¡ ")
    print("=" * 70)
    
    checks = [
        ('import re', 're ëª¨ë“ˆ ì„í¬íŠ¸ (CoT íŒŒì‹±ìš©)', True),
        ('def _extract_output_from_cot(self, hint: str) -> str:', 'CoT íŒŒì‹± ë©”ì„œë“œ', True),
        ("re.search(r'<output>(.*?)</output>', hint, re.DOTALL", 'output íƒœê·¸ íŒŒì‹±', True),
        ("re.search(r'<thinking>(.*?)</thinking>', hint, re.DOTALL", 'thinking íƒœê·¸ íŒŒì‹±', True),
        ('hint = self._extract_output_from_cot(hint)', 'CoT íŒŒì‹± í˜¸ì¶œ', True),
        ('print(f"[CoT] <output> íƒœê·¸ ë°œê²¬', 'CoT íŒŒì‹± ë¡œê¹…', True),
        ('print(f"[CoT] <thinking> ë‚´ìš©', 'thinking ë¡œê¹…', True),
    ]
    
    passed = check_file_content('models/model_inference.py', checks, 'VLLMInference ê²€ì¦')
    results.append(('model_inference.py', passed))
    
    # ìµœì¢… ê²°ê³¼
    print("\n" + "=" * 70)
    print("ğŸ“Š ìµœì¢… ê²€ì¦ ê²°ê³¼")
    print("=" * 70)
    
    for filename, passed in results:
        status = "âœ… í†µê³¼" if passed else "âŒ ì‹¤íŒ¨"
        print(f"  {filename:30s}: {status}")
    
    all_passed = all(r[1] for r in results)
    
    print("\n" + "=" * 70)
    if all_passed:
        print("ğŸ‰ ëª¨ë“  ê²€ì¦ í†µê³¼!")
        print("\nâœ… ì›Œí¬í”Œë¡œìš° ìš”ì•½:")
        print("   1. app.py â†’ student_codeë¥¼ prompt_generator.generate_prompt()ì— ì „ë‹¬")
        print("   2. adaptive_prompt.py â†’ student_codeë¥¼ edu_engine.generate_*_prompt()ì— ì „ë‹¬")
        print("   3. educational_prompts.py â†’ student_codeë¥¼ í”„ë¡¬í”„íŠ¸ f-stringì— ì‚½ì…")
        print("   4. educational_prompts.py â†’ CoT <thinking>/<output> íƒœê·¸ í¬í•¨")
        print("   5. model_inference.py â†’ CoT íŒŒì‹±í•˜ì—¬ <output>ë§Œ ì¶”ì¶œ")
        print("\nâœ… ì„í¬íŠ¸ ì²´ì¸:")
        print("   app.py â†’ AdaptivePromptGenerator")
        print("   adaptive_prompt.py â†’ EducationalPromptEngine")
        print("   app.py â†’ VLLMInference")
        print("\nâœ… ëª¨ë“  êµ¬ê°„ì—ì„œ student_codeê°€ ì˜¬ë°”ë¥´ê²Œ ì „ë‹¬ë©ë‹ˆë‹¤!")
    else:
        print("âš ï¸  ì¼ë¶€ ê²€ì¦ ì‹¤íŒ¨. ìœ„ì˜ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
    print("=" * 70)


if __name__ == '__main__':
    main()
