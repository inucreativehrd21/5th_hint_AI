"""
ë³´ì•ˆ í•„í„°ë§ ì‹œìŠ¤í…œ
- ì•…ì§ˆ ì‚¬ìš©ì ê³µê²© ë°©ì–´
- í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ë°©ì§€
- í† í° ë‚­ë¹„ ê³µê²© ë°©ì–´
- Rate Limiting
"""
import re
import time
from typing import Dict, Tuple, List
from dataclasses import dataclass
from datetime import datetime, timedelta


@dataclass
class SecurityCheckResult:
    """ë³´ì•ˆ ê²€ì‚¬ ê²°ê³¼"""
    is_safe: bool
    risk_level: str  # 'safe', 'warning', 'danger'
    blocked_reasons: List[str]
    sanitized_input: str


class SecurityGuard:
    """ë³´ì•ˆ ê°€ë“œ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # Rate Limiting: ì‚¬ìš©ìë³„ ìš”ì²­ ê¸°ë¡
        self.request_history: Dict[str, List[datetime]] = {}
        
        # ì•…ì§ˆ íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤
        self.malicious_patterns = self._load_malicious_patterns()
        
        # ì„¤ì •
        self.max_requests_per_minute = 10
        self.max_requests_per_hour = 50
        self.max_code_length = 5000
        self.max_prompt_length = 2000
    
    def _load_malicious_patterns(self) -> Dict[str, List[str]]:
        """ì•…ì§ˆ ê³µê²© íŒ¨í„´ ë¡œë“œ"""
        return {
            # í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ê³µê²©
            'prompt_injection': [
                r'ignore\s+(previous|all|above)\s+instructions?',
                r'forget\s+(everything|all|previous)',
                r'you\s+are\s+now',
                r'new\s+instructions?:',
                r'system\s*:\s*',
                r'<\|im_start\|>',
                r'<\|im_end\|>',
                r'\[INST\]',
                r'\[/INST\]',
                r'###\s*System',
                r'###\s*Human',
                r'###\s*Assistant',
                r'</s>',
                r'<s>',
            ],
            
            # Jailbreak ì‹œë„
            'jailbreak': [
                r'DAN\s+mode',
                r'developer\s+mode',
                r'unrestricted\s+mode',
                r'bypass\s+(safety|filter|restriction)',
                r'ignore\s+(ethics|safety|policy)',
                r'roleplay\s+as\s+(evil|hacker|malicious)',
                r'pretend\s+you\s+are',
            ],
            
            # í† í° ë‚­ë¹„ ê³µê²©
            'token_waste': [
                r'(.)\1{50,}',  # ê°™ì€ ë¬¸ì 50íšŒ ì´ìƒ ë°˜ë³µ
                r'[\w\s]{10000,}',  # 10000ì ì´ìƒ í…ìŠ¤íŠ¸
                r'(print|echo|output).*\*\s*\d{4,}',  # ì—„ì²­ë‚œ ë°˜ë³µ ìš”ì²­
            ],
            
            # ì½”ë“œ ì‹¤í–‰ ê³µê²©
            'code_injection': [
                r'__import__\s*\(',
                r'eval\s*\(',
                r'exec\s*\(',
                r'compile\s*\(',
                r'os\.(system|popen|spawn)',
                r'subprocess\.',
                r'open\s*\(.*(w|a)\+?',  # íŒŒì¼ ì“°ê¸°
                r'requests?\.(get|post|put|delete)',  # ì™¸ë¶€ ìš”ì²­
                r'socket\.',
            ],
            
            # ë¯¼ê° ì •ë³´ ìš”ì²­
            'sensitive_info': [
                r'(api|secret|password|token|key)\s*[:=]',
                r'\.env',
                r'config\.(json|yaml|yml|ini)',
                r'/etc/(passwd|shadow)',
                r'database\s+credentials?',
            ],
        }
    
    def check_input_safety(self, user_code: str, user_id: str = "anonymous") -> SecurityCheckResult:
        """ì…ë ¥ ì•ˆì „ì„± ì¢…í•© ê²€ì‚¬"""
        blocked_reasons = []
        risk_level = 'safe'
        
        # 1. Rate Limiting ì²´í¬
        if not self._check_rate_limit(user_id):
            blocked_reasons.append("â±ï¸ ìš”ì²­ ì†ë„ ì œí•œ ì´ˆê³¼ (Rate Limit)")
            risk_level = 'danger'
        
        # 2. ì…ë ¥ ê¸¸ì´ ì²´í¬
        if len(user_code) > self.max_code_length:
            blocked_reasons.append(f"ğŸ“ ì½”ë“œ ê¸¸ì´ ì´ˆê³¼ (ìµœëŒ€ {self.max_code_length}ì)")
            risk_level = 'danger'
        
        # 3. ì•…ì§ˆ íŒ¨í„´ íƒì§€
        detected_attacks = self._detect_malicious_patterns(user_code)
        if detected_attacks:
            blocked_reasons.extend(detected_attacks)
            risk_level = 'danger'
        
        # 4. ì½”ë“œ êµ¬ì¡° ê²€ì¦
        structure_issues = self._validate_code_structure(user_code)
        if structure_issues:
            blocked_reasons.extend(structure_issues)
            if risk_level == 'safe':
                risk_level = 'warning'
        
        # 5. ì…ë ¥ ì •ì œ
        sanitized_input = self._sanitize_input(user_code)
        
        is_safe = risk_level != 'danger'
        
        return SecurityCheckResult(
            is_safe=is_safe,
            risk_level=risk_level,
            blocked_reasons=blocked_reasons,
            sanitized_input=sanitized_input
        )
    
    def _check_rate_limit(self, user_id: str) -> bool:
        """Rate Limiting ê²€ì‚¬"""
        now = datetime.now()
        
        # ì‚¬ìš©ì ì´ë ¥ ì´ˆê¸°í™”
        if user_id not in self.request_history:
            self.request_history[user_id] = []
        
        # ì˜¤ë˜ëœ ê¸°ë¡ ì •ë¦¬ (1ì‹œê°„ ì´ìƒ)
        self.request_history[user_id] = [
            req_time for req_time in self.request_history[user_id]
            if now - req_time < timedelta(hours=1)
        ]
        
        # ë¶„ë‹¹ ìš”ì²­ ì²´í¬
        recent_requests = [
            req_time for req_time in self.request_history[user_id]
            if now - req_time < timedelta(minutes=1)
        ]
        
        if len(recent_requests) >= self.max_requests_per_minute:
            return False
        
        # ì‹œê°„ë‹¹ ìš”ì²­ ì²´í¬
        if len(self.request_history[user_id]) >= self.max_requests_per_hour:
            return False
        
        # ìš”ì²­ ê¸°ë¡
        self.request_history[user_id].append(now)
        return True
    
    def _detect_malicious_patterns(self, text: str) -> List[str]:
        """ì•…ì§ˆ íŒ¨í„´ íƒì§€"""
        detected = []
        
        text_lower = text.lower()
        
        for attack_type, patterns in self.malicious_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text_lower, re.IGNORECASE):
                    detected.append(f"ğŸš¨ {attack_type.upper()} ê³µê²© ê°ì§€: {pattern[:50]}")
                    break  # ê° ê³µê²© íƒ€ì…ë‹¹ 1íšŒë§Œ ë³´ê³ 
        
        return detected
    
    def _validate_code_structure(self, code: str) -> List[str]:
        """ì½”ë“œ êµ¬ì¡° ê²€ì¦"""
        issues = []
        
        # ë¹ˆ ì½”ë“œ
        if not code.strip():
            return issues
        
        # ë¹„ì •ìƒì ì¸ ë°˜ë³µ
        lines = code.split('\n')
        if len(lines) > 500:
            issues.append("âš ï¸ ë¹„ì •ìƒì ìœ¼ë¡œ ê¸´ ì½”ë“œ (500ì¤„ ì´ˆê³¼)")
        
        # ë™ì¼ ì¤„ ë°˜ë³µ
        unique_lines = set(line.strip() for line in lines if line.strip())
        if len(lines) > 50 and len(unique_lines) < len(lines) * 0.3:
            issues.append("âš ï¸ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì½”ë“œ ë°˜ë³µ íŒ¨í„´")
        
        # ì£¼ì„ë§Œ ìˆëŠ” ì½”ë“œ
        code_lines = [line for line in lines if line.strip() and not line.strip().startswith('#')]
        if len(code_lines) == 0 and len(lines) > 10:
            issues.append("âš ï¸ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ì—†ìŒ (ì£¼ì„ë§Œ ì¡´ì¬)")
        
        return issues
    
    def _sanitize_input(self, text: str) -> str:
        """ì…ë ¥ ì •ì œ"""
        # ê¸¸ì´ ì œí•œ
        if len(text) > self.max_code_length:
            text = text[:self.max_code_length]
        
        # ìœ„í—˜í•œ íŠ¹ìˆ˜ë¬¸ì ì œê±°
        text = re.sub(r'[<>]', '', text)
        
        # ì—°ì† ê³µë°± ì •ë¦¬
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
    
    def validate_hint_request(self, code: str, problem_id: str, 
                             selected_level: str, user_id: str = "anonymous") -> Tuple[bool, str]:
        """íŒíŠ¸ ìš”ì²­ ì „ì²´ ê²€ì¦"""
        # 1. ë³´ì•ˆ ê²€ì‚¬
        security_result = self.check_input_safety(code, user_id)
        
        if not security_result.is_safe:
            reasons = '\n'.join(security_result.blocked_reasons)
            return False, f"âŒ ë³´ì•ˆ ê²€ì¦ ì‹¤íŒ¨:\n{reasons}"
        
        # 2. ì…ë ¥ ìœ íš¨ì„±
        if not code.strip():
            return False, "âŒ ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
        
        if not problem_id:
            return False, "âŒ ë¬¸ì œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."
        
        if selected_level not in ['novice', 'intermediate', 'advanced']:
            return False, "âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ë‚œì´ë„ì…ë‹ˆë‹¤."
        
        # 3. ê²½ê³  ë©”ì‹œì§€
        if security_result.risk_level == 'warning':
            warnings = '\n'.join(security_result.blocked_reasons)
            return True, f"âš ï¸ ê²½ê³ :\n{warnings}\n\nê³„ì† ì§„í–‰í•©ë‹ˆë‹¤."
        
        return True, "âœ… ê²€ì¦ í†µê³¼"
    
    def get_usage_stats(self, user_id: str) -> Dict:
        """ì‚¬ìš©ì ì‚¬ìš©ëŸ‰ í†µê³„"""
        if user_id not in self.request_history:
            return {
                'total_requests': 0,
                'requests_last_minute': 0,
                'requests_last_hour': 0,
                'remaining_minute': self.max_requests_per_minute,
                'remaining_hour': self.max_requests_per_hour
            }
        
        now = datetime.now()
        history = self.request_history[user_id]
        
        recent_minute = [
            req for req in history 
            if now - req < timedelta(minutes=1)
        ]
        
        recent_hour = [
            req for req in history 
            if now - req < timedelta(hours=1)
        ]
        
        return {
            'total_requests': len(history),
            'requests_last_minute': len(recent_minute),
            'requests_last_hour': len(recent_hour),
            'remaining_minute': max(0, self.max_requests_per_minute - len(recent_minute)),
            'remaining_hour': max(0, self.max_requests_per_hour - len(recent_hour))
        }


# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤
_security_guard = None

def get_security_guard() -> SecurityGuard:
    """ì‹±ê¸€í†¤ SecurityGuard ì¸ìŠ¤í„´ìŠ¤"""
    global _security_guard
    if _security_guard is None:
        _security_guard = SecurityGuard()
    return _security_guard
